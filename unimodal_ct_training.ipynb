{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PietroCaforio/research-biocv-proj/blob/dev/unimodal_ct_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wT0Xulxcazs"
      },
      "source": [
        "# Train unimodal CT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PietroCaforio/research-biocv-proj\n",
        "!cd research-biocv-proj && git switch dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQPpMHPTdnk_",
        "outputId": "10321258-c017-4fae-c80a-9d5ce765ec03"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'research-biocv-proj' already exists and is not an empty directory.\n",
            "M\tdata/processed/labels.txt\n",
            "M\tdata/processed/overfit.txt\n",
            "M\tdata/processed/train.txt\n",
            "M\tdata/processed/val.txt\n",
            "Already on 'dev'\n",
            "Your branch is up to date with 'origin/dev'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd research-biocv-proj && git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f30MPnMfhPLY",
        "outputId": "26aabced-39e1-48d7-adc9-11ab5449e4aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 652 bytes | 2.00 KiB/s, done.\n",
            "From https://github.com/PietroCaforio/research-biocv-proj\n",
            "   36cb07f..dce0f07  dev        -> origin/dev\n",
            "Updating 36cb07f..dce0f07\n",
            "Fast-forward\n",
            " data/unimodal.py    |   1 \u001b[32m+\u001b[m\n",
            " preprocessing.ipynb | 586 \u001b[32m+\u001b[m\u001b[31m-----------------------------------------------------------------------\u001b[m\n",
            " 2 files changed, 7 insertions(+), 580 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke8uIXW8sPTn",
        "outputId": "2f65c21e-b440-4404-c54a-7be9bf65b9bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o /content/drive/MyDrive/processed57PatientsCPTAC-PDA.zip -d research-biocv-proj/data/"
      ],
      "metadata": {
        "id": "TguAR9j41BBP",
        "outputId": "0507aed6-612c-4b4e-994a-79f664d652ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/processed57PatientsCPTAC-PDA.zip\n",
            "   creating: research-biocv-proj/data/processed/CT/\n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-00189.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-00599.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-00622.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-00625.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-01032.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-01036.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-01687.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-01689.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-01703.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-02109.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-02112.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-02116.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-02118.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-02606.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-02610.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-02613.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-02890.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-03356.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-03622.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-03628.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-03632.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-03639.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-03743.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-04479.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-04848.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3L-04853.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-00249.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-00302.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-00303.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-00511.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-00512.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-00513.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-00514.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-00518.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-00957.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-01012.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-01166.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-01167.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-01382.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-01502.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-01714.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-01715.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-01716.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-01897.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-02010.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-02295.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-02592.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-02971.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-02997.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-03000.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-03006.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-03007.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-03039.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-03426.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-03430.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-03670.npy  \n",
            "  inflating: research-biocv-proj/data/processed/CT/C3N-03754.npy  \n",
            "  inflating: research-biocv-proj/data/processed/labels.txt  \n",
            "  inflating: research-biocv-proj/data/processed/overfit.txt  \n",
            "  inflating: research-biocv-proj/data/processed/train.txt  \n",
            "  inflating: research-biocv-proj/data/processed/val.txt  \n",
            "   creating: research-biocv-proj/data/processed/WSI/\n",
            "   creating: research-biocv-proj/data/processed/WSI/G1/\n",
            "   creating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/\n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_0.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_1.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_10.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_11.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_12.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_13.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_14.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_15.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_2.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_3.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_4.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_5.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_6.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_7.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_8.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00599/patch_9.npy  \n",
            "   creating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/\n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_0.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_1.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_10.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_11.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_12.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_13.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_14.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_15.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_2.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_3.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_4.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_5.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_6.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_7.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_8.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G1/C3L-00622/patch_9.npy  \n",
            "   creating: research-biocv-proj/data/processed/WSI/G2/\n",
            "   creating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/\n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_0.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_1.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_10.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_11.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_12.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_13.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_14.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_15.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_2.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_3.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_4.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_5.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_6.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_7.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_8.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00189/patch_9.npy  \n",
            "   creating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/\n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_0.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_1.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_10.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_11.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_12.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_13.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_14.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_15.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_2.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_3.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_4.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_5.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_6.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_7.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_8.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00401/patch_9.npy  \n",
            "   creating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/\n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_0.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_1.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_10.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_11.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_12.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_13.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_14.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_15.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_2.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_3.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_4.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_5.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_6.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_7.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_8.npy  \n",
            "  inflating: research-biocv-proj/data/processed/WSI/G2/C3L-00625/patch_9.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qKtI7Fw8cazu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add the 'data' directory to sys.path\n",
        "sys.path.append(str(Path('research-biocv-proj').resolve()))\n",
        "from data.unimodal import *\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the dataset\n",
        "dataset = UnimodalCTDataset(split='train', dataset_path = \"research-biocv-proj/data/processed/\")\n",
        "\n",
        "# Check the length of the dataset\n",
        "print(f\"Dataset length: {len(dataset)}\")\n",
        "\n",
        "# Check the first few items in the dataset\n",
        "for i in range(3):\n",
        "    item = dataset[i]\n",
        "    print(f\"Item {i}:\")\n",
        "    print(f\"  Patient ID: {item['patient_id']}\")\n",
        "    print(f\"  Frame shape: {item['frame'].shape}\")\n",
        "    print(f\"  Label: {item['label']}\")\n",
        "\n",
        "# Check if DataLoader works with the dataset\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Get a batch of data\n",
        "batch = next(iter(dataloader))\n",
        "\n",
        "# Check the batch\n",
        "print(f\"Batch patient IDs: {batch['patient_id']}\")\n",
        "print(f\"Batch frame shape: {batch['frame'].shape}\")\n",
        "print(f\"Batch labels: {batch['label']}\")\n",
        "\n",
        "# Move batch to device (e.g., GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset.move_batch_to_device(batch, device)\n",
        "print(f\"Batch moved to device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flFTYnq5eTCz",
        "outputId": "889408c1-c5b8-443f-b36c-69c8e9e636e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset length: 1508\n",
            "Item 0:\n",
            "  Patient ID: C3N-02295\n",
            "  Frame shape: (3, 244, 244)\n",
            "  Label: 0\n",
            "Item 1:\n",
            "  Patient ID: C3N-02295\n",
            "  Frame shape: (3, 244, 244)\n",
            "  Label: 0\n",
            "Item 2:\n",
            "  Patient ID: C3N-02295\n",
            "  Frame shape: (3, 244, 244)\n",
            "  Label: 0\n",
            "Batch patient IDs: ['C3N-02295', 'C3N-01167', 'C3N-02971', 'C3N-00511']\n",
            "Batch frame shape: torch.Size([4, 3, 244, 244])\n",
            "Batch labels: tensor([0, 1, 0, 1])\n",
            "Batch moved to device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train ResNet model"
      ],
      "metadata": {
        "id": "Gp9YPOpaKZvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import ResNetForImageClassification"
      ],
      "metadata": {
        "id": "_tomn2dZKTt7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = UnimodalCTDataset(split='train',dataset_path = \"research-biocv-proj/data/processed/\" )\n",
        "val_dataset = UnimodalCTDataset(split='val',dataset_path = \"research-biocv-proj/data/processed/\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "n7GSh8vBKvoo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNetForImageClassification.from_pretrained('microsoft/resnet-50')\n",
        "model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, UnimodalCTDataset.num_classes) #Adjusting the final layer to the unimodal number of classes"
      ],
      "metadata": {
        "id": "DAKnbV64LVPu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "SdAtOMb6MdNS",
        "outputId": "b0286e03-577a-48a5-dcd9-ba37368a63fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetForImageClassification(\n",
              "  (resnet): ResNetModel(\n",
              "    (embedder): ResNetEmbeddings(\n",
              "      (embedder): ResNetConvLayer(\n",
              "        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (encoder): ResNetEncoder(\n",
              "      (stages): ModuleList(\n",
              "        (0): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBottleNeckLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (2): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBottleNeckLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (2): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (3): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBottleNeckLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (2): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (3): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (4): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (5): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBottleNeckLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (2): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=2048, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        frames = batch['frame'].float().to(device)\n",
        "        labels = batch['label'].long().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(frames)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            frames = batch['frame'].float().to(device)\n",
        "            labels = batch['label'].long().to(device)\n",
        "\n",
        "            outputs = model(frames)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100 * correct / total}\")"
      ],
      "metadata": {
        "id": "gCxaYwfPNEaJ",
        "outputId": "16542628-e7ce-481e-e524-17daa5a42853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.0592137624820073\n",
            "Validation Loss: 1.2411746762015603, Accuracy: 28.994082840236686\n",
            "Epoch 2, Loss: 0.8851653796931108\n",
            "Validation Loss: 1.2608912587165833, Accuracy: 26.035502958579883\n",
            "Epoch 3, Loss: 0.5710877794772387\n",
            "Validation Loss: 1.3317241126840764, Accuracy: 32.84023668639053\n",
            "Epoch 4, Loss: 0.2592886191171904\n",
            "Validation Loss: 1.6602858819744803, Accuracy: 34.319526627218934\n",
            "Epoch 5, Loss: 0.0797419825491185\n",
            "Validation Loss: 1.6466393281113019, Accuracy: 35.798816568047336\n",
            "Epoch 6, Loss: 0.03332264575874433\n",
            "Validation Loss: 1.742036103524945, Accuracy: 35.20710059171598\n",
            "Epoch 7, Loss: 0.033611166678989925\n",
            "Validation Loss: 1.9169988357885317, Accuracy: 32.248520710059175\n",
            "Epoch 8, Loss: 0.021630875038681552\n",
            "Validation Loss: 2.117519408633763, Accuracy: 37.27810650887574\n",
            "Epoch 9, Loss: 0.02499554595851805\n",
            "Validation Loss: 2.221602893688462, Accuracy: 39.053254437869825\n",
            "Epoch 10, Loss: 0.02655997553180593\n",
            "Validation Loss: 2.2758993872187356, Accuracy: 35.20710059171598\n",
            "Epoch 11, Loss: 0.009981012485998994\n",
            "Validation Loss: 2.207449695603414, Accuracy: 34.9112426035503\n",
            "Epoch 12, Loss: 0.01796551581355743\n",
            "Validation Loss: 2.563285165551034, Accuracy: 36.3905325443787\n",
            "Epoch 13, Loss: 0.00911408457371484\n",
            "Validation Loss: 2.1059668402780187, Accuracy: 35.50295857988166\n",
            "Epoch 14, Loss: 0.003996795584195449\n",
            "Validation Loss: 2.2487433789805933, Accuracy: 34.319526627218934\n",
            "Epoch 15, Loss: 0.0026378064661306175\n",
            "Validation Loss: 2.231298129666935, Accuracy: 34.9112426035503\n",
            "Epoch 16, Loss: 0.014799597154099805\n",
            "Validation Loss: 2.359052594920451, Accuracy: 35.50295857988166\n",
            "Epoch 17, Loss: 0.0061803128143462045\n",
            "Validation Loss: 2.4571059539236804, Accuracy: 34.319526627218934\n",
            "Epoch 18, Loss: 0.002344420091200542\n",
            "Validation Loss: 2.3863441351462495, Accuracy: 36.3905325443787\n",
            "Epoch 19, Loss: 0.029804315871539682\n",
            "Validation Loss: 2.6590459663420916, Accuracy: 32.84023668639053\n",
            "Epoch 20, Loss: 0.01788024003811491\n",
            "Validation Loss: 3.0141886736858976, Accuracy: 35.798816568047336\n",
            "Epoch 21, Loss: 0.0111378527750882\n",
            "Validation Loss: 2.6126236666671256, Accuracy: 32.84023668639053\n",
            "Epoch 22, Loss: 0.005351379537993732\n",
            "Validation Loss: 2.711626314219426, Accuracy: 34.9112426035503\n",
            "Epoch 23, Loss: 0.008071627674022844\n",
            "Validation Loss: 2.968860056843947, Accuracy: 35.798816568047336\n",
            "Epoch 24, Loss: 0.004680007788313863\n",
            "Validation Loss: 2.7795845321485433, Accuracy: 33.43195266272189\n",
            "Epoch 25, Loss: 0.0019430587447762566\n",
            "Validation Loss: 2.6063028960700403, Accuracy: 36.094674556213015\n",
            "Epoch 26, Loss: 0.0017240355949373527\n",
            "Validation Loss: 2.610252447637983, Accuracy: 36.3905325443787\n",
            "Epoch 27, Loss: 0.02282323143238803\n",
            "Validation Loss: 2.732086553069001, Accuracy: 36.98224852071006\n",
            "Epoch 28, Loss: 0.004682824324845569\n",
            "Validation Loss: 2.605278490280563, Accuracy: 33.13609467455621\n",
            "Epoch 29, Loss: 0.006014594488685058\n",
            "Validation Loss: 2.694260206242854, Accuracy: 30.473372781065088\n",
            "Epoch 30, Loss: 0.011238776318350574\n",
            "Validation Loss: 2.581722155171023, Accuracy: 34.023668639053255\n",
            "Epoch 31, Loss: 0.013770783736011557\n",
            "Validation Loss: 2.556467749940401, Accuracy: 34.9112426035503\n",
            "Epoch 32, Loss: 0.009931600621105948\n",
            "Validation Loss: 2.44470998111435, Accuracy: 35.50295857988166\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d713cea86ef4>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/research-biocv-proj/data/unimodal.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mitem_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatient_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mscan_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"CT/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpatient_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mscan_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscan_frame\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         return {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    454\u001b[0m                                           max_header_size=max_header_size)\n\u001b[1;32m    455\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    457\u001b[0m                                          \u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                                          max_header_size=max_header_size)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JeC7PrYxO7eQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}