{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9547833,"sourceType":"datasetVersion","datasetId":5664308},{"sourceId":9609374,"sourceType":"datasetVersion","datasetId":5863281}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":20449.755857,"end_time":"2024-09-20T21:22:44.003990","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-20T15:41:54.248133","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0f74e50d11824c589594423e545fb4fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"143ad20d35434be89f39cdac70e0081d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"148dbfbb28564c9392b3e506f8ad78d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a4a435278744922ba00185fa0628e06","IPY_MODEL_a290bba08f9542f9bf35798535d390d9","IPY_MODEL_4dc614faa4bd4cf9a688353619da2b0e"],"layout":"IPY_MODEL_655f98d76beb4cfdbd790f0620af4fce"}},"19c4b812c58d4ab6bc3cd5d7bea9fdf8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dc614faa4bd4cf9a688353619da2b0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19c4b812c58d4ab6bc3cd5d7bea9fdf8","placeholder":"​","style":"IPY_MODEL_b13021f1f89f4786a7353648fc1a5884","value":" 46.8M/46.8M [00:03&lt;00:00, 15.1MB/s]"}},"5aabee46e73c4e1e949fe611f697add0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e578b3fcc5c437791b41c60ead2f373":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6213dd8318994913b79d296acfb123b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e578b3fcc5c437791b41c60ead2f373","max":69548,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5aabee46e73c4e1e949fe611f697add0","value":69548}},"62de300bb21143b68602e94c74e3f39b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"655f98d76beb4cfdbd790f0620af4fce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a4a435278744922ba00185fa0628e06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1e9deee886e441990c8086b244101b2","placeholder":"​","style":"IPY_MODEL_143ad20d35434be89f39cdac70e0081d","value":"model.safetensors: 100%"}},"70c0081ec8cf4159b2cd1184eae53b5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dd733ad658b48359feb02f8c0436c62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f4be5cd22f64a6ebf8629388d9fe314":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f98e6a28a77b460aa5b9c367684afbf6","IPY_MODEL_6213dd8318994913b79d296acfb123b7","IPY_MODEL_97a6dfab7007407cac133d69ba3394c0"],"layout":"IPY_MODEL_7fe107f7ec564556bbd41a700510e787"}},"7fe107f7ec564556bbd41a700510e787":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c90ff6ae7f44ed1a6a8496e9269d845":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97a6dfab7007407cac133d69ba3394c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70c0081ec8cf4159b2cd1184eae53b5d","placeholder":"​","style":"IPY_MODEL_e7c6b1c1c6304d2ca4e35472b1f690b4","value":" 69.5k/69.5k [00:00&lt;00:00, 326kB/s]"}},"a290bba08f9542f9bf35798535d390d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dd733ad658b48359feb02f8c0436c62","max":46812324,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c90ff6ae7f44ed1a6a8496e9269d845","value":46812324}},"b13021f1f89f4786a7353648fc1a5884":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7c6b1c1c6304d2ca4e35472b1f690b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1e9deee886e441990c8086b244101b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f98e6a28a77b460aa5b9c367684afbf6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62de300bb21143b68602e94c74e3f39b","placeholder":"​","style":"IPY_MODEL_0f74e50d11824c589594423e545fb4fd","value":"config.json: 100%"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### <a href=\"https://www.kaggle.com/code/pietrocaforio/unimodal-ct-training-kaggle?scriptVersionId=197281783\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{"papermill":{"duration":0.01088,"end_time":"2024-09-20T15:41:57.036467","exception":false,"start_time":"2024-09-20T15:41:57.025587","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Train 3D unimodal CT","metadata":{"papermill":{"duration":0.009918,"end_time":"2024-09-20T15:41:57.056687","exception":false,"start_time":"2024-09-20T15:41:57.046769","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!git clone https://github.com/PietroCaforio/research-biocv-proj\n!cd research-biocv-proj && git switch dev","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:41:57.078438Z","iopub.status.busy":"2024-09-20T15:41:57.078050Z","iopub.status.idle":"2024-09-20T15:42:00.045694Z","shell.execute_reply":"2024-09-20T15:42:00.044449Z"},"papermill":{"duration":2.98145,"end_time":"2024-09-20T15:42:00.048282","exception":false,"start_time":"2024-09-20T15:41:57.066832","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd research-biocv-proj && git pull","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:00.074018Z","iopub.status.busy":"2024-09-20T15:42:00.073015Z","iopub.status.idle":"2024-09-20T15:42:01.364978Z","shell.execute_reply":"2024-09-20T15:42:01.363387Z"},"papermill":{"duration":1.307855,"end_time":"2024-09-20T15:42:01.367874","exception":false,"start_time":"2024-09-20T15:42:00.060019","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:01.392749Z","iopub.status.busy":"2024-09-20T15:42:01.392353Z","iopub.status.idle":"2024-09-20T15:42:15.984053Z","shell.execute_reply":"2024-09-20T15:42:15.982986Z"},"papermill":{"duration":14.606752,"end_time":"2024-09-20T15:42:15.986576","exception":false,"start_time":"2024-09-20T15:42:01.379824","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"3d_wandb_key\")","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:16.011902Z","iopub.status.busy":"2024-09-20T15:42:16.011121Z","iopub.status.idle":"2024-09-20T15:42:16.234449Z","shell.execute_reply":"2024-09-20T15:42:16.233396Z"},"papermill":{"duration":0.239115,"end_time":"2024-09-20T15:42:16.237192","exception":false,"start_time":"2024-09-20T15:42:15.998077","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login(key=secret_value_0)","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:16.263930Z","iopub.status.busy":"2024-09-20T15:42:16.263019Z","iopub.status.idle":"2024-09-20T15:42:18.623923Z","shell.execute_reply":"2024-09-20T15:42:18.622840Z"},"papermill":{"duration":2.376595,"end_time":"2024-09-20T15:42:18.626187","exception":false,"start_time":"2024-09-20T15:42:16.249592","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nfrom pathlib import Path\n\n# Add the 'data' directory to sys.path\nsys.path.append(str(Path('research-biocv-proj').resolve()))\nfrom data.unimodal3D import *\nfrom pathlib import Path\n\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\n\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:18.652568Z","iopub.status.busy":"2024-09-20T15:42:18.651887Z","iopub.status.idle":"2024-09-20T15:42:23.023030Z","shell.execute_reply":"2024-09-20T15:42:23.022140Z"},"papermill":{"duration":4.38677,"end_time":"2024-09-20T15:42:23.025341","exception":false,"start_time":"2024-09-20T15:42:18.638571","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train ResNet model","metadata":{"papermill":{"duration":0.012235,"end_time":"2024-09-20T15:42:23.050247","exception":false,"start_time":"2024-09-20T15:42:23.038012","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print            \n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model,config, run_name=None):\n    wandb.init(\n        # set the wandb project where this run will be logged\n        project=\"3Dunimodal_ct_training\",\n        name = run_name,\n        # track hyperparameters and run metadata\n        config=config\n    )\n    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n    if config[\"class_weights\"] is not None: \n        config[\"class_weights\"] = torch.tensor(config[\"class_weights\"], dtype=torch.float).to(device)\n    \n    if config[\"focal_loss\"] is not None:\n        criterion = FocalLoss(gamma = config[\"focal_loss\"])\n    else:\n        criterion = nn.CrossEntropyLoss(weight = config[\"class_weights\"])\n    \n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor = config[\"reduce_lr_factor\"], patience = config[\"patience\"])\n    # initialize the early_stopping object\n    early_stopping = None\n    if config[\"early_stop_patience\"] is not None:\n        early_stopping = EarlyStopping(patience=config[\"early_stop_patience\"], verbose=True)\n    \n    # Training loop\n    num_epochs = config[\"epochs\"]\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        train_correct = 0\n        total = 0\n        correct_per_class = [0, 0, 0]  # For G1, G2, G3\n        total_per_class = [0, 0, 0]  # For G1, G2, G3\n        for batch in train_loader:\n            volumes = batch['volume'].float().to(device)\n            labels = batch['label'].long().to(device)\n            #print(f\"volumes batch dimensions: {volumes.size()}\")\n            optimizer.zero_grad()\n            outputs = model(volumes.unsqueeze(1))\n            \n            if config[\"focal_loss\"]:\n                softmax = torch.nn.Softmax(dim=-1)\n                loss = criterion(softmax(outputs), labels)\n            else:\n                loss = criterion(outputs, labels)\n            \n            _, predicted = torch.max(outputs, 1)\n            train_correct += (predicted == labels).sum().item()\n            loss.backward()\n            optimizer.step()\n            total += labels.size(0)\n            running_loss += loss.item()\n            \n            # Calculate accuracy per class\n            for i in range(3):  # We have 3 classes: G1 (0), G2 (1), G3 (2)\n                correct_per_class[i] += ((predicted == i) & (labels == i)).sum().item()\n                total_per_class[i] += (labels == i).sum().item()\n            #if epoch % 100 == 0:\n                #for num,volume in enumerate(batch[\"volume\"]):\n                    #np.save(f\"batch{epoch}_vol{num}\",volume)\n\n        train_accuracy = 100 * train_correct / total\n        class_accuracy = [(100 * correct_per_class[i] / total_per_class[i]) if total_per_class[i] > 0 else 0 for i in range(3)]\n        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n        wandb.log({\"Train Accuracy\": train_accuracy, \"Train loss\": running_loss/len(train_loader), \"G1_TrainAcc\":class_accuracy[0], \"G2_TrainAcc\":class_accuracy[1], \"G3_TrainAcc\":class_accuracy[2]})\n\n        # Validation loop\n        model.eval()\n        val_loss = 0.0\n        correct = 0\n        total = 0\n        # Initialize counters for each class (G1, G2, G3)\n        correct_per_class = [0, 0, 0]  # For G1, G2, G3\n        total_per_class = [0, 0, 0]  # For G1, G2, G3\n\n        with torch.no_grad():\n            for batch in val_loader:\n                volumes = batch['volume'].float().to(device)\n                labels = batch['label'].long().to(device)\n                \n                outputs = model(volumes.unsqueeze(1))\n                if config[\"focal_loss\"]:\n                    softmax = torch.nn.Softmax(dim=-1)\n                    loss = criterion(softmax(outputs), labels)\n                else:\n                    loss = criterion(outputs, labels)\n                \n                val_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n                # Calculate accuracy per class\n                for i in range(3):  # We have 3 classes: G1 (0), G2 (1), G3 (2)\n                    correct_per_class[i] += ((predicted == i) & (labels == i)).sum().item()\n                    total_per_class[i] += (labels == i).sum().item()\n                #if epoch % 100 == 0:\n                    #for num,volume in enumerate(batch[\"volume\"]):\n                       # np.save(f\"batch{epoch}_vol{num}_validation\",volume)\n        scheduler.step(val_loss)\n        # Compute total accuracy and per-class accuracy\n        total_accuracy = 100 * correct / total\n        class_accuracy = [(100 * correct_per_class[i] / total_per_class[i]) if total_per_class[i] > 0 else 0 for i in range(3)]\n        print(f\"Validation Loss: {val_loss/len(val_loader)}, Total Accuracy: {total_accuracy:.2f}%\")\n        print(f\"Accuracy per class - G1: {class_accuracy[0]:.2f}%, G2: {class_accuracy[1]:.2f}%, G3: {class_accuracy[2]:.2f}%\")\n        # log metrics to wandb\n        wandb.log({\"Total Accuracy\": total_accuracy, \"Validation Loss\": val_loss/len(val_loader), \"G1_Acc\":class_accuracy[0], \"G2_Acc\":class_accuracy[1], \"G3_Acc\":class_accuracy[2]})\n        if config[\"early_stop_patience\"] is not None:\n            early_stopping(val_loss, model)\n        \n        if config[\"early_stop_patience\"] is not None:\n            if early_stopping.early_stop:\n                print(\"Early stopping\")\n                break\n    wandb.finish()   ","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:23.076273Z","iopub.status.busy":"2024-09-20T15:42:23.075661Z","iopub.status.idle":"2024-09-20T15:42:23.098243Z","shell.execute_reply":"2024-09-20T15:42:23.097224Z"},"papermill":{"duration":0.03811,"end_time":"2024-09-20T15:42:23.100409","exception":false,"start_time":"2024-09-20T15:42:23.062299","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nfrom transformers import ResNetForImageClassification","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:23.127067Z","iopub.status.busy":"2024-09-20T15:42:23.126628Z","iopub.status.idle":"2024-09-20T15:42:25.127631Z","shell.execute_reply":"2024-09-20T15:42:25.126484Z"},"papermill":{"duration":2.017418,"end_time":"2024-09-20T15:42:25.130350","exception":false,"start_time":"2024-09-20T15:42:23.112932","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = UnimodalCTDataset3D(split='train',dataset_path = \"/kaggle/input/processed57patients3d/processed_3D_pad\" )\nval_dataset = UnimodalCTDataset3D(split='val',dataset_path = \"/kaggle/input/processed57patients3d/processed_3D_pad\")\n\ntrain_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:25.159019Z","iopub.status.busy":"2024-09-20T15:42:25.157910Z","iopub.status.idle":"2024-09-20T15:42:36.074180Z","shell.execute_reply":"2024-09-20T15:42:36.073250Z"},"papermill":{"duration":10.933528,"end_time":"2024-09-20T15:42:36.076557","exception":false,"start_time":"2024-09-20T15:42:25.143029","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Training set stats:{train_dataset.stats()}\")\nprint(f\"Validation set stats:{val_dataset.stats()}\")","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:36.103572Z","iopub.status.busy":"2024-09-20T15:42:36.103123Z","iopub.status.idle":"2024-09-20T15:42:36.108485Z","shell.execute_reply":"2024-09-20T15:42:36.107458Z"},"papermill":{"duration":0.021518,"end_time":"2024-09-20T15:42:36.110968","exception":false,"start_time":"2024-09-20T15:42:36.089450","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = []\nfor sample in train_dataset:\n    labels.append(sample[\"label\"])\nlabels = np.array(labels)\nclass_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:36.136873Z","iopub.status.busy":"2024-09-20T15:42:36.136505Z","iopub.status.idle":"2024-09-20T15:42:37.103948Z","shell.execute_reply":"2024-09-20T15:42:37.102735Z"},"papermill":{"duration":0.983442,"end_time":"2024-09-20T15:42:37.106661","exception":false,"start_time":"2024-09-20T15:42:36.123219","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(class_weights)","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:37.133948Z","iopub.status.busy":"2024-09-20T15:42:37.133600Z","iopub.status.idle":"2024-09-20T15:42:37.139709Z","shell.execute_reply":"2024-09-20T15:42:37.138637Z"},"papermill":{"duration":0.021987,"end_time":"2024-09-20T15:42:37.141886","exception":false,"start_time":"2024-09-20T15:42:37.119899","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3D Resnet-18","metadata":{"papermill":{"duration":0.011896,"end_time":"2024-09-20T15:42:37.165970","exception":false,"start_time":"2024-09-20T15:42:37.154074","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torchvision.models as models","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:37.192282Z","iopub.status.busy":"2024-09-20T15:42:37.191493Z","iopub.status.idle":"2024-09-20T15:42:38.217785Z","shell.execute_reply":"2024-09-20T15:42:38.216959Z"},"papermill":{"duration":1.042504,"end_time":"2024-09-20T15:42:38.220199","exception":false,"start_time":"2024-09-20T15:42:37.177695","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet3D(nn.Module):\n    def __init__(self, num_classes):\n        super(ResNet3D, self).__init__()\n        self.model = models.video.r3d_18(pretrained=True)  # 3D ResNet18\n        self.model.stem[0] = nn.Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:38.246616Z","iopub.status.busy":"2024-09-20T15:42:38.245878Z","iopub.status.idle":"2024-09-20T15:42:38.252677Z","shell.execute_reply":"2024-09-20T15:42:38.251770Z"},"papermill":{"duration":0.02191,"end_time":"2024-09-20T15:42:38.254645","exception":false,"start_time":"2024-09-20T15:42:38.232735","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ResNet34-3D","metadata":{}},{"cell_type":"code","source":"import math\nfrom functools import partial\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef get_inplanes():\n    return [64, 128, 256, 512]\n\n\ndef conv3x3x3(in_planes, out_planes, stride=1):\n    return nn.Conv3d(in_planes,\n                     out_planes,\n                     kernel_size=3,\n                     stride=stride,\n                     padding=1,\n                     bias=False)\n\n\ndef conv1x1x1(in_planes, out_planes, stride=1):\n    return nn.Conv3d(in_planes,\n                     out_planes,\n                     kernel_size=1,\n                     stride=stride,\n                     bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, downsample=None):\n        super().__init__()\n\n        self.conv1 = conv3x3x3(in_planes, planes, stride)\n        self.bn1 = nn.BatchNorm3d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3x3(planes, planes)\n        self.bn2 = nn.BatchNorm3d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1, downsample=None):\n        super().__init__()\n\n        self.conv1 = conv1x1x1(in_planes, planes)\n        self.bn1 = nn.BatchNorm3d(planes)\n        self.conv2 = conv3x3x3(planes, planes, stride)\n        self.bn2 = nn.BatchNorm3d(planes)\n        self.conv3 = conv1x1x1(planes, planes * self.expansion)\n        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self,\n                 block,\n                 layers,\n                 block_inplanes,\n                 n_input_channels=3,\n                 conv1_t_size=7,\n                 conv1_t_stride=1,\n                 no_max_pool=False,\n                 shortcut_type='B',\n                 widen_factor=1.0,\n                 n_classes=400):\n        super().__init__()\n\n        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n\n        self.in_planes = block_inplanes[0]\n        self.no_max_pool = no_max_pool\n\n        self.conv1 = nn.Conv3d(n_input_channels,\n                               self.in_planes,\n                               kernel_size=(conv1_t_size, 7, 7),\n                               stride=(conv1_t_stride, 2, 2),\n                               padding=(conv1_t_size // 2, 3, 3),\n                               bias=False)\n        self.bn1 = nn.BatchNorm3d(self.in_planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, block_inplanes[0], layers[0],\n                                       shortcut_type)\n        self.layer2 = self._make_layer(block,\n                                       block_inplanes[1],\n                                       layers[1],\n                                       shortcut_type,\n                                       stride=2)\n        self.layer3 = self._make_layer(block,\n                                       block_inplanes[2],\n                                       layers[2],\n                                       shortcut_type,\n                                       stride=2)\n        self.layer4 = self._make_layer(block,\n                                       block_inplanes[3],\n                                       layers[3],\n                                       shortcut_type,\n                                       stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.fc = nn.Linear(block_inplanes[3] * block.expansion, n_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                nn.init.kaiming_normal_(m.weight,\n                                        mode='fan_out',\n                                        nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm3d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _downsample_basic_block(self, x, planes, stride):\n        out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n        zero_pads = torch.zeros(out.size(0), planes - out.size(1), out.size(2),\n                                out.size(3), out.size(4))\n        if isinstance(out.data, torch.cuda.FloatTensor):\n            zero_pads = zero_pads.cuda()\n\n        out = torch.cat([out.data, zero_pads], dim=1)\n\n        return out\n\n    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n        downsample = None\n        if stride != 1 or self.in_planes != planes * block.expansion:\n            if shortcut_type == 'A':\n                downsample = partial(self._downsample_basic_block,\n                                     planes=planes * block.expansion,\n                                     stride=stride)\n            else:\n                downsample = nn.Sequential(\n                    conv1x1x1(self.in_planes, planes * block.expansion, stride),\n                    nn.BatchNorm3d(planes * block.expansion))\n\n        layers = []\n        layers.append(\n            block(in_planes=self.in_planes,\n                  planes=planes,\n                  stride=stride,\n                  downsample=downsample))\n        self.in_planes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.in_planes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        if not self.no_max_pool:\n            x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef generate_model(model_depth, **kwargs):\n    assert model_depth in [10, 18, 34, 50, 101, 152, 200]\n\n    if model_depth == 10:\n        model = ResNet(BasicBlock, [1, 1, 1, 1], get_inplanes(), **kwargs)\n    elif model_depth == 18:\n        model = ResNet(BasicBlock, [2, 2, 2, 2], get_inplanes(), **kwargs)\n    elif model_depth == 34:\n        model = ResNet(BasicBlock, [3, 4, 6, 3], get_inplanes(), **kwargs)\n    elif model_depth == 50:\n        model = ResNet(Bottleneck, [3, 4, 6, 3], get_inplanes(), **kwargs)\n    elif model_depth == 101:\n        model = ResNet(Bottleneck, [3, 4, 23, 3], get_inplanes(), **kwargs)\n    elif model_depth == 152:\n        model = ResNet(Bottleneck, [3, 8, 36, 3], get_inplanes(), **kwargs)\n    elif model_depth == 200:\n        model = ResNet(Bottleneck, [3, 24, 36, 3], get_inplanes(), **kwargs)\n\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = ResNet3D(num_classes = 3)","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:38.279528Z","iopub.status.busy":"2024-09-20T15:42:38.279236Z","iopub.status.idle":"2024-09-20T15:42:39.703752Z","shell.execute_reply":"2024-09-20T15:42:39.702669Z"},"papermill":{"duration":1.440209,"end_time":"2024-09-20T15:42:39.706568","exception":false,"start_time":"2024-09-20T15:42:38.266359","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = generate_model(34, n_input_channels = 1, n_classes = 3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:39.738265Z","iopub.status.busy":"2024-09-20T15:42:39.737277Z","iopub.status.idle":"2024-09-20T15:42:40.001816Z","shell.execute_reply":"2024-09-20T15:42:40.000859Z"},"papermill":{"duration":0.280962,"end_time":"2024-09-20T15:42:40.004019","exception":false,"start_time":"2024-09-20T15:42:39.723057","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://github.com/mathiaszinnen/focal_loss_torch/tree/main\n!pip install focal_loss_torch","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from focal_loss.focal_loss import FocalLoss\nconfig={\n    \"learning_rate\": 1e-7,\n    \"architecture\": \"ResNet3D-34 FocalLoss\",\n    \"epochs\": 400,\n    \"weight_decay\": 5e-4,\n    \"reduce_lr_factor\": 0.25,\n    \"patience\": 40,\n    \"class_weights\": None,\n    \"early_stop_patience\": None,\n    \"focal_loss\": 3\n    }\ntrain(model, config, run_name = config[\"architecture\"])","metadata":{"execution":{"iopub.execute_input":"2024-09-20T15:42:40.031708Z","iopub.status.busy":"2024-09-20T15:42:40.031377Z","iopub.status.idle":"2024-09-20T21:22:41.302046Z","shell.execute_reply":"2024-09-20T21:22:41.301255Z"},"papermill":{"duration":20401.287066,"end_time":"2024-09-20T21:22:41.304389","exception":false,"start_time":"2024-09-20T15:42:40.017323","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}