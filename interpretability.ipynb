{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9300ed25",
   "metadata": {},
   "source": [
    "# Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799cc1d2",
   "metadata": {},
   "source": [
    "Sul fold migliore vado a fare forward pass e calcolarmi i gradienti, i positional embedding, correlazioni, curvatura e path degli input che danno quei risultati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc296b",
   "metadata": {},
   "source": [
    "Pensiero random (potrebbe essere carino per la tesi e quasi d‚Äôobbligo per il paper), lo lascerei comunque come ultimo step se abbiamo tempo: riusciamo sulla fold che va meglio, del dataset che va meglio per il nostro modello tenere traccia in validation di quali sono le coppie di feature (in modo da rintracciare la coppia rad-histo) che portano gradienti maggiori e minori e salvare le rispettive correlazioni (e calcolare il rischio)? Questo significa rintracciare le coppie la cui correlazione ha un‚Äôimportanza o meno nel calcolo del rischio.\n",
    "Quello che sarebbe interessante far vedere sono gli estremi opposti su due coppie di rad histo con:\n",
    "Alta correlazione, alto gradiente, alto risk score, basso survival, alto grado di tumore: sulla radiologia calcolare tipo regolarit√† della forma (che ci i aspetta bassa, usando la segmentazione), grandezza tumore (che ci si aspetta alta, usando la segmentazione) e sulla histo il numero di cellule epiteliali cancerogene (che ci si aspetta alta, cosa che si pu√≤ fare con una rete pretrainata) \n",
    "Alta correlazione, basso gradiente, basso risk score, alto survival, basso grado di tumore: sulla radiologia calcolare tipo regolarit√† della forma (che ci i aspetta alta), grandezza tumore (che ci si aspetta bassa, usando la segmentazione) e sulla histo il numero di cellule epiteliali cancerogene (che ci si aspetta bassa, cosa che si pu√≤ fare con una rete pretrainata) \n",
    "Se tu ti occupi di tracciare i gradienti/correlazioni/file (non dovrebbe essere troppo complesso, basta salvarsi le combinazioni di risultati su un file), io mi occuperei di tutto il resto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e07be3",
   "metadata": {},
   "source": [
    "### Define Functions for interpretability analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eea5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import csv\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data.multimodal_features_surv import MultimodalCTWSIDatasetSurv\n",
    "from models.dpe.main_model_nobackbone_surv_new_gcs import MADPENetNoBackbonesSurv\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "\n",
    "class CoxLoss(_WeightedLoss):\n",
    "    def forward(self, hazard_pred: torch.Tensor, survtime: torch.Tensor, censor: torch.Tensor):\n",
    "        censor = censor.float()\n",
    "        n = len(survtime)\n",
    "        # risk‚Äëset matrix\n",
    "        R_mat = survtime.reshape((1, n)) >= survtime.reshape((n, 1))\n",
    "        theta = hazard_pred.reshape(-1)\n",
    "        exp_theta = torch.exp(theta)\n",
    "        # negative log‚Äëpartial likelihood\n",
    "        loss = -torch.mean((theta - torch.log(torch.sum(exp_theta * R_mat, dim=1))) * censor)\n",
    "        return loss\n",
    "\n",
    "\n",
    "def compute_grad_and_curvature(fused_features, hazard, survtime, censor):\n",
    "    hazard = hazard.view(-1)\n",
    "    loss = CoxLoss()(hazard, survtime, censor)\n",
    "    # first derivative\n",
    "    grad_f = torch.autograd.grad(loss, fused_features, create_graph=True)[0]\n",
    "    grad_norm = grad_f.flatten(1).norm(p=2, dim=1)\n",
    "\n",
    "    # Hutchinson estimator for Hessian diagonal\n",
    "    random_vec = grad_f.detach().clone().sign()\n",
    "    grad_dot_random = torch.sum(grad_f * random_vec)\n",
    "    hvp = torch.autograd.grad(grad_dot_random, fused_features, retain_graph=False)[0]\n",
    "    curvature = torch.sum(hvp * random_vec, dim=list(range(1, hvp.ndim)))\n",
    "\n",
    "    return grad_norm.detach().cpu().numpy(), curvature.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def evaluate_and_log(folds_dir, ct_path, wsi_path, test_path, output_dir, batch_size=16, n_folds=5):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        print(f\"\\n=== Fold {fold} ===\")\n",
    "        model = MADPENetNoBackbonesSurv(\n",
    "            rad_input_dim=1024, histo_input_dim=768,\n",
    "            inter_dim=256, token_dim=256, dim_hider=256\n",
    "        )\n",
    "        model.eval()\n",
    "\n",
    "        # Load checkpoint\n",
    "        fold_dir = os.path.join(folds_dir, f\"fold_{fold}\")\n",
    "        model_subdir = next(d for d in os.listdir(fold_dir)\n",
    "                            if os.path.isdir(os.path.join(fold_dir, d)))\n",
    "        model_file = next(f for f in os.listdir(os.path.join(fold_dir, model_subdir))\n",
    "                          if f.endswith(\"mixed_missing.pth\"))\n",
    "        checkpoint = torch.load(\n",
    "            os.path.join(fold_dir, model_subdir, model_file), map_location=\"cpu\"\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        dataset = MultimodalCTWSIDatasetSurv(\n",
    "            fold=fold,\n",
    "            split=\"test\",\n",
    "            ct_path=ct_path,\n",
    "            wsi_path=wsi_path,\n",
    "            labels_splits_path=test_path,\n",
    "            missing_modality_prob=0.0,\n",
    "            require_both_modalities=False,\n",
    "            pairing_mode=\"one_to_one\",\n",
    "            allow_repeats=True,\n",
    "            pairs_per_patient=None,\n",
    "            missing_modality=\"wsi\"\n",
    "        )\n",
    "\n",
    "        loader = DataLoader(dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=0)\n",
    "\n",
    "        # CSV Logger\n",
    "        log_file = os.path.join(output_dir, f\"fold_{fold}_log.csv\")\n",
    "        fold_tensor_dir = os.path.join(output_dir, f\"fold_{fold}\")\n",
    "        os.makedirs(fold_tensor_dir, exist_ok=True)\n",
    "\n",
    "        with open(log_file, \"w\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([\n",
    "                \"patient_id\", \"ct_path\", \"wsi_path\",\n",
    "                \"ct_available\", \"wsi_available\",\n",
    "                \"hazard_score\", \"survtime\", \"censor\",\n",
    "                \"grad_norm\", \"curvature\",\n",
    "                \"fused_path\", \"pe_path\", \"hazard_tensor_path\"\n",
    "            ])\n",
    "\n",
    "            sample_counter = 0\n",
    "            for batch in loader:\n",
    "                # ensure floats\n",
    "                for k, v in batch.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        batch[k] = v.float()\n",
    "\n",
    "                with torch.enable_grad():\n",
    "                    for v in batch.values():\n",
    "                        if isinstance(v, torch.Tensor):\n",
    "                            v.requires_grad = True\n",
    "\n",
    "                    outputs = model(\n",
    "                        batch[\"ct_feature\"],\n",
    "                        batch[\"wsi_feature\"],\n",
    "                        modality_flag=batch[\"modality_mask\"],\n",
    "                        output_layers=[\"hazard\", \"fused_features\", \"positional_embeddings\"]\n",
    "                    )\n",
    "                    hazard = outputs[\"hazard\"].squeeze(1)  # [B]\n",
    "                    fused_features = outputs[\"fused_features\"]    # [B, D]\n",
    "                    pos_emb = outputs[\"positional_embeddings\"]    # [B, D]\n",
    "\n",
    "                    grad_norms, curvatures = compute_grad_and_curvature(\n",
    "                        fused_features, hazard,\n",
    "                        batch[\"survtime\"], batch[\"censor\"]\n",
    "                    )\n",
    "\n",
    "                # save per-sample\n",
    "                B = hazard.size(0)\n",
    "                for j in range(B):\n",
    "                    sample_id = f\"sample_{sample_counter:06d}\"\n",
    "                    fused_path = os.path.join(fold_tensor_dir, f\"{sample_id}_fused.npy\")\n",
    "                    pe_path = os.path.join(fold_tensor_dir, f\"{sample_id}_pe.npy\")\n",
    "                    hazard_path = os.path.join(fold_tensor_dir, f\"{sample_id}_hazard.npy\")\n",
    "\n",
    "                    np.save(fused_path, fused_features[j].detach().cpu().numpy())\n",
    "                    np.save(pe_path, pos_emb[j].detach().cpu().numpy())\n",
    "                    np.save(hazard_path, hazard[j].detach().cpu().numpy())\n",
    "\n",
    "                    ct_flag = int(batch[\"modality_mask\"][j, 0].item())\n",
    "                    wsi_flag = int(batch[\"modality_mask\"][j, 1].item())\n",
    "                    if batch[\"censor\"][j].item()==0: continue\n",
    "                    writer.writerow([\n",
    "                        batch[\"patient_id\"][j],\n",
    "                        dataset.samples[sample_counter][\"ct_path\"],\n",
    "                        dataset.samples[sample_counter][\"wsi_feature\"],\n",
    "                        ct_flag, wsi_flag,\n",
    "                        hazard[j].item(),\n",
    "                        batch[\"survtime\"][j].item(),\n",
    "                        batch[\"censor\"][j].item(),\n",
    "                        grad_norms[j], curvatures[j],\n",
    "                        fused_path, pe_path, hazard_path\n",
    "                    ])\n",
    "\n",
    "                    sample_counter += 1\n",
    "                    \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "def find_topk_gradient_extremes(\n",
    "    csv_path: str,\n",
    "    k: int = 10,\n",
    "    output_dir: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds top-k highest and lowest |gradient norm| samples from a CSV log.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to fold_X_log.csv generated during eval.\n",
    "        k (int): Number of top and bottom samples to retrieve.\n",
    "        output_dir (str): Optional folder to save CSVs. If None, only prints results.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if \"grad_norm\" not in df.columns:\n",
    "        raise ValueError(\"The CSV does not contain 'grad_norm' column.\")\n",
    "\n",
    "    # Compute absolute gradient norms\n",
    "    df[\"abs_grad_norm\"] = df[\"grad_norm\"].abs()\n",
    "\n",
    "    # Sort by absolute gradient norm\n",
    "    df_sorted = df.sort_values(by=\"abs_grad_norm\", ascending=True)\n",
    "\n",
    "    topk_low = df_sorted.head(k).copy()\n",
    "    topk_high = df_sorted.tail(k).copy()[::-1]  # High to low\n",
    "\n",
    "    print(\"\\nüîπ Top-k LOW |Gradient Norm| Samples:\")\n",
    "    print(topk_low[[\"patient_id\", \"grad_norm\", \"abs_grad_norm\", \"ct_available\", \"wsi_available\"]])\n",
    "\n",
    "    print(\"\\nüî∏ Top-k HIGH |Gradient Norm| Samples:\")\n",
    "    print(topk_high[[\"patient_id\", \"grad_norm\", \"abs_grad_norm\", \"ct_available\", \"wsi_available\"]])\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        low_path = os.path.join(output_dir, \"topk_low_gradient.csv\")\n",
    "        high_path = os.path.join(output_dir, \"topk_high_gradient.csv\")\n",
    "        topk_low.to_csv(low_path, index=False)\n",
    "        topk_high.to_csv(high_path, index=False)\n",
    "        print(f\"\\nüìÅ Saved to:\\n  {low_path}\\n  {high_path}\")\n",
    "\n",
    "    return topk_low, topk_high\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    # Example usage\n",
    "#    for i in range(4):\n",
    "#        csv_input = f\"./interpretability/interpretability_UCEC_mixed50/fold_{i}_log.csv\"\n",
    "#        find_topk_gradient_extremes(\n",
    "#            csv_path=csv_input,\n",
    "#            k=15,\n",
    "#            output_dir=f\"./interpretability/interpretability_UCEC_mixed50/fold_{i}_topk\"\n",
    "#        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246042e8",
   "metadata": {},
   "source": [
    "## SET GLOBAL SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41f464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "SEED = 0\n",
    "\n",
    "def set_global_seed(seed=SEED):\n",
    "    \"\"\"\n",
    "    Set a global seed for reproducibility across different libraries and random number generators.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed value to be used\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_global_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7e068e",
   "metadata": {},
   "source": [
    "## CPTAC-PDA train-mixed 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "273a21a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 0 ===\n",
      "\n",
      "=== Fold 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 2 ===\n",
      "\n",
      "=== Fold 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 4 ===\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1   C3L-04479   0.012782       0.012782             1              1\n",
      "5   C3N-02573   0.017344       0.017344             0              1\n",
      "3   C3N-02573   0.017345       0.017345             0              1\n",
      "4   C3N-02573   0.017345       0.017345             0              1\n",
      "10  C3N-03839   0.018279       0.018279             0              1\n",
      "12  C3N-03839   0.018280       0.018280             0              1\n",
      "11  C3N-03839   0.018280       0.018280             0              1\n",
      "9   C3N-03839   0.018288       0.018288             0              1\n",
      "2   C3L-04479   0.021653       0.021653             1              1\n",
      "0   C3L-02897   0.022701       0.022701             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "6   C3N-02940   0.024397       0.024397             0              1\n",
      "8   C3N-02940   0.024366       0.024366             0              1\n",
      "7   C3N-02940   0.024363       0.024363             0              1\n",
      "0   C3L-02897   0.022701       0.022701             0              1\n",
      "2   C3L-04479   0.021653       0.021653             1              1\n",
      "9   C3N-03839   0.018288       0.018288             0              1\n",
      "11  C3N-03839   0.018280       0.018280             0              1\n",
      "12  C3N-03839   0.018280       0.018280             0              1\n",
      "10  C3N-03839   0.018279       0.018279             0              1\n",
      "4   C3N-02573   0.017345       0.017345             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_pda_mixed50/fold_0_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_pda_mixed50/fold_0_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "9   C3L-04027        0.0            0.0             0              1\n",
      "16  C3N-02585        0.0            0.0             0              1\n",
      "15  C3N-02010        0.0            0.0             1              1\n",
      "14  C3N-02010        0.0            0.0             1              1\n",
      "12  C3L-04027        0.0            0.0             0              1\n",
      "11  C3L-04027        0.0            0.0             0              1\n",
      "10  C3L-04027        0.0            0.0             0              1\n",
      "17  C3N-02585        0.0            0.0             0              1\n",
      "18  C3N-02585        0.0            0.0             0              1\n",
      "7   C3L-04027        0.0            0.0             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "13  C3N-01012   0.111465       0.111465             1              1\n",
      "0   C3L-03356   0.024508       0.024508             1              1\n",
      "8   C3L-04027   0.000000       0.000000             0              1\n",
      "1   C3L-03630   0.000000       0.000000             0              1\n",
      "2   C3L-03630   0.000000       0.000000             0              1\n",
      "3   C3L-03630   0.000000       0.000000             0              1\n",
      "4   C3L-03630   0.000000       0.000000             0              1\n",
      "5   C3L-04027   0.000000       0.000000             0              1\n",
      "6   C3L-04027   0.000000       0.000000             0              1\n",
      "7   C3L-04027   0.000000       0.000000             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_pda_mixed50/fold_1_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_pda_mixed50/fold_1_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0   C3L-01031   0.000000       0.000000             0              1\n",
      "1   C3L-01031   0.000000       0.000000             0              1\n",
      "2   C3L-01031   0.000000       0.000000             0              1\n",
      "10  C3N-03006   0.000000       0.000000             0              1\n",
      "11  C3N-03006   0.000000       0.000000             0              1\n",
      "12  C3N-03840   0.000000       0.000000             0              1\n",
      "13  C3N-03840   0.000000       0.000000             0              1\n",
      "14  C3N-03840   0.000000       0.000000             0              1\n",
      "5   C3N-00198   0.001869       0.001869             1              1\n",
      "7   C3N-00198   0.002016       0.002016             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "3   C3L-02109   0.005569       0.005569             1              1\n",
      "4   C3L-02109   0.005567       0.005567             1              1\n",
      "8   C3N-00198   0.002197       0.002197             1              1\n",
      "6   C3N-00198   0.002194       0.002194             1              1\n",
      "9   C3N-00198   0.002019       0.002019             1              1\n",
      "7   C3N-00198   0.002016       0.002016             1              1\n",
      "5   C3N-00198   0.001869       0.001869             1              1\n",
      "14  C3N-03840   0.000000       0.000000             0              1\n",
      "13  C3N-03840   0.000000       0.000000             0              1\n",
      "12  C3N-03840   0.000000       0.000000             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_pda_mixed50/fold_2_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_pda_mixed50/fold_2_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "10  C3L-03123   0.000371       0.000371             1              1\n",
      "14  C3N-03665   0.002209       0.002209             0              1\n",
      "13  C3N-03665   0.002209       0.002209             0              1\n",
      "0   C3L-01124   0.002632       0.002632             0              1\n",
      "2   C3L-01124   0.002632       0.002632             0              1\n",
      "1   C3L-01124   0.002632       0.002632             0              1\n",
      "5   C3L-02463   0.002934       0.002934             0              1\n",
      "8   C3L-02463   0.002934       0.002934             0              1\n",
      "6   C3L-02463   0.002934       0.002934             0              1\n",
      "4   C3L-02463   0.002934       0.002934             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "9   C3L-03123   0.018076       0.018076             1              1\n",
      "12  C3N-03173   0.004833       0.004833             0              1\n",
      "11  C3N-03173   0.004833       0.004833             0              1\n",
      "3   C3L-02463   0.002934       0.002934             0              1\n",
      "7   C3L-02463   0.002934       0.002934             0              1\n",
      "4   C3L-02463   0.002934       0.002934             0              1\n",
      "6   C3L-02463   0.002934       0.002934             0              1\n",
      "8   C3L-02463   0.002934       0.002934             0              1\n",
      "5   C3L-02463   0.002934       0.002934             0              1\n",
      "1   C3L-01124   0.002632       0.002632             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_pda_mixed50/fold_3_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_pda_mixed50/fold_3_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id     grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "16  C3N-03086  6.599083e-08   6.599083e-08             0              1\n",
      "17  C3N-03086  6.834765e-08   6.834765e-08             0              1\n",
      "2   C3L-00017  3.451168e-03   3.451168e-03             0              1\n",
      "1   C3L-00017  3.451228e-03   3.451228e-03             0              1\n",
      "4   C3L-00017  3.451334e-03   3.451334e-03             0              1\n",
      "0   C3L-00017  3.452077e-03   3.452077e-03             0              1\n",
      "3   C3L-00017  3.452539e-03   3.452539e-03             0              1\n",
      "15  C3N-03086  9.884519e-03   9.884519e-03             0              1\n",
      "14  C3N-02944  1.317976e-02   1.317976e-02             0              1\n",
      "12  C3N-02944  1.317983e-02   1.317983e-02             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "11  C3L-01328   0.016834       0.016834             0              1\n",
      "5   C3L-00589   0.016322       0.016322             0              1\n",
      "6   C3L-00589   0.016320       0.016320             0              1\n",
      "7   C3L-00589   0.016319       0.016319             0              1\n",
      "8   C3L-01328   0.015808       0.015808             0              1\n",
      "9   C3L-01328   0.015808       0.015808             0              1\n",
      "10  C3L-01328   0.015808       0.015808             0              1\n",
      "13  C3N-02944   0.013180       0.013180             0              1\n",
      "12  C3N-02944   0.013180       0.013180             0              1\n",
      "14  C3N-02944   0.013180       0.013180             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_pda_mixed50/fold_4_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_pda_mixed50/fold_4_topk/topk_high_gradient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    }
   ],
   "source": [
    "folds_dir = \"./models/ckpts/CPTACPDA_trainmixed50_multival_Titan_MedImSight_redone\"\n",
    "test_path = \"./data/processed/processed_CPTAC_PDA_survival/k=all.tsv\"\n",
    "ct_path = \"../MedImageInsights/embeddings_output_cptacpda_93\"\n",
    "wsi_path = \"../../TitanCPTACPDA/20x_512px_0px_overlap/slide_features_titan\"\n",
    "output_dir = \"./interpretability/interpretability_pda_mixed50\"\n",
    "evaluate_and_log(folds_dir,ct_path,wsi_path,test_path,output_dir,batch_size=16)\n",
    "for i in range(5):\n",
    "    csv_input = f\"./interpretability/interpretability_pda_mixed50/fold_{i}_log.csv\"\n",
    "    find_topk_gradient_extremes(\n",
    "        csv_path=csv_input,\n",
    "        k=10,\n",
    "        output_dir=f\"./interpretability/interpretability_pda_mixed50/fold_{i}_topk\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2953750f",
   "metadata": {},
   "source": [
    "## CPTAC-PDA train-mixed 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0489a9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3 ===\n",
      "\n",
      "=== Fold 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1   C3L-04479   0.000917       0.000917             1              1\n",
      "10  C3N-03839   0.008852       0.008852             0              1\n",
      "12  C3N-03839   0.008852       0.008852             0              1\n",
      "11  C3N-03839   0.008852       0.008852             0              1\n",
      "9   C3N-03839   0.008852       0.008852             0              1\n",
      "0   C3L-02897   0.010575       0.010575             0              1\n",
      "5   C3N-02573   0.011518       0.011518             0              1\n",
      "4   C3N-02573   0.011518       0.011518             0              1\n",
      "3   C3N-02573   0.011518       0.011518             0              1\n",
      "6   C3N-02940   0.011803       0.011803             0              1\n",
      "8   C3N-02940   0.011803       0.011803             0              1\n",
      "7   C3N-02940   0.011803       0.011803             0              1\n",
      "2   C3L-04479   0.111472       0.111472             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "2   C3L-04479   0.111472       0.111472             1              1\n",
      "7   C3N-02940   0.011803       0.011803             0              1\n",
      "8   C3N-02940   0.011803       0.011803             0              1\n",
      "6   C3N-02940   0.011803       0.011803             0              1\n",
      "3   C3N-02573   0.011518       0.011518             0              1\n",
      "4   C3N-02573   0.011518       0.011518             0              1\n",
      "5   C3N-02573   0.011518       0.011518             0              1\n",
      "0   C3L-02897   0.010575       0.010575             0              1\n",
      "9   C3N-03839   0.008852       0.008852             0              1\n",
      "11  C3N-03839   0.008852       0.008852             0              1\n",
      "12  C3N-03839   0.008852       0.008852             0              1\n",
      "10  C3N-03839   0.008852       0.008852             0              1\n",
      "1   C3L-04479   0.000917       0.000917             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed30/fold_0_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed30/fold_0_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "14  C3N-02010   0.003045       0.003045             1              1\n",
      "15  C3N-02010   0.003491       0.003491             1              1\n",
      "6   C3L-04027   0.005069       0.005069             0              1\n",
      "5   C3L-04027   0.005069       0.005069             0              1\n",
      "7   C3L-04027   0.005070       0.005070             0              1\n",
      "16  C3N-02585   0.005799       0.005799             0              1\n",
      "17  C3N-02585   0.005799       0.005799             0              1\n",
      "18  C3N-02585   0.005800       0.005800             0              1\n",
      "9   C3L-04027   0.007031       0.007031             0              1\n",
      "8   C3L-04027   0.007031       0.007031             0              1\n",
      "10  C3L-04027   0.007031       0.007031             0              1\n",
      "11  C3L-04027   0.007031       0.007031             0              1\n",
      "12  C3L-04027   0.007031       0.007031             0              1\n",
      "0   C3L-03356   0.007792       0.007792             1              1\n",
      "2   C3L-03630   0.008212       0.008212             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "13  C3N-01012   0.013103       0.013103             1              1\n",
      "4   C3L-03630   0.008213       0.008213             0              1\n",
      "1   C3L-03630   0.008212       0.008212             0              1\n",
      "3   C3L-03630   0.008212       0.008212             0              1\n",
      "2   C3L-03630   0.008212       0.008212             0              1\n",
      "0   C3L-03356   0.007792       0.007792             1              1\n",
      "12  C3L-04027   0.007031       0.007031             0              1\n",
      "11  C3L-04027   0.007031       0.007031             0              1\n",
      "10  C3L-04027   0.007031       0.007031             0              1\n",
      "8   C3L-04027   0.007031       0.007031             0              1\n",
      "9   C3L-04027   0.007031       0.007031             0              1\n",
      "18  C3N-02585   0.005800       0.005800             0              1\n",
      "17  C3N-02585   0.005799       0.005799             0              1\n",
      "16  C3N-02585   0.005799       0.005799             0              1\n",
      "7   C3L-04027   0.005070       0.005070             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed30/fold_1_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed30/fold_1_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "13  C3N-03840   0.000006       0.000006             0              1\n",
      "12  C3N-03840   0.001234       0.001234             0              1\n",
      "14  C3N-03840   0.001265       0.001265             0              1\n",
      "11  C3N-03006   0.002409       0.002409             0              1\n",
      "10  C3N-03006   0.004594       0.004594             0              1\n",
      "6   C3N-00198   0.008535       0.008535             1              1\n",
      "8   C3N-00198   0.011774       0.011774             1              1\n",
      "2   C3L-01031   0.012447       0.012447             0              1\n",
      "1   C3L-01031   0.012464       0.012464             0              1\n",
      "5   C3N-00198   0.013080       0.013080             1              1\n",
      "7   C3N-00198   0.013944       0.013944             1              1\n",
      "0   C3L-01031   0.016662       0.016662             0              1\n",
      "3   C3L-02109   0.017103       0.017103             1              1\n",
      "4   C3L-02109   0.026745       0.026745             1              1\n",
      "9   C3N-00198   0.048932       0.048932             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "9   C3N-00198   0.048932       0.048932             1              1\n",
      "4   C3L-02109   0.026745       0.026745             1              1\n",
      "3   C3L-02109   0.017103       0.017103             1              1\n",
      "0   C3L-01031   0.016662       0.016662             0              1\n",
      "7   C3N-00198   0.013944       0.013944             1              1\n",
      "5   C3N-00198   0.013080       0.013080             1              1\n",
      "1   C3L-01031   0.012464       0.012464             0              1\n",
      "2   C3L-01031   0.012447       0.012447             0              1\n",
      "8   C3N-00198   0.011774       0.011774             1              1\n",
      "6   C3N-00198   0.008535       0.008535             1              1\n",
      "10  C3N-03006   0.004594       0.004594             0              1\n",
      "11  C3N-03006   0.002409       0.002409             0              1\n",
      "14  C3N-03840   0.001265       0.001265             0              1\n",
      "12  C3N-03840   0.001234       0.001234             0              1\n",
      "13  C3N-03840   0.000006       0.000006             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed30/fold_2_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed30/fold_2_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "13  C3N-03665   0.000111       0.000111             0              1\n",
      "14  C3N-03665   0.000111       0.000111             0              1\n",
      "0   C3L-01124   0.002588       0.002588             0              1\n",
      "1   C3L-01124   0.002588       0.002588             0              1\n",
      "2   C3L-01124   0.002588       0.002588             0              1\n",
      "6   C3L-02463   0.005099       0.005099             0              1\n",
      "5   C3L-02463   0.005099       0.005099             0              1\n",
      "8   C3L-02463   0.005099       0.005099             0              1\n",
      "3   C3L-02463   0.005099       0.005099             0              1\n",
      "4   C3L-02463   0.005099       0.005099             0              1\n",
      "7   C3L-02463   0.005099       0.005099             0              1\n",
      "11  C3N-03173   0.007634       0.007634             0              1\n",
      "12  C3N-03173   0.007634       0.007634             0              1\n",
      "9   C3L-03123   0.013923       0.013923             1              1\n",
      "10  C3L-03123   0.089948       0.089948             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "10  C3L-03123   0.089948       0.089948             1              1\n",
      "9   C3L-03123   0.013923       0.013923             1              1\n",
      "12  C3N-03173   0.007634       0.007634             0              1\n",
      "11  C3N-03173   0.007634       0.007634             0              1\n",
      "7   C3L-02463   0.005099       0.005099             0              1\n",
      "4   C3L-02463   0.005099       0.005099             0              1\n",
      "3   C3L-02463   0.005099       0.005099             0              1\n",
      "8   C3L-02463   0.005099       0.005099             0              1\n",
      "5   C3L-02463   0.005099       0.005099             0              1\n",
      "6   C3L-02463   0.005099       0.005099             0              1\n",
      "2   C3L-01124   0.002588       0.002588             0              1\n",
      "1   C3L-01124   0.002588       0.002588             0              1\n",
      "0   C3L-01124   0.002588       0.002588             0              1\n",
      "14  C3N-03665   0.000111       0.000111             0              1\n",
      "13  C3N-03665   0.000111       0.000111             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed30/fold_3_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed30/fold_3_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id     grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "16  C3N-03086  6.166599e-08   6.166599e-08             0              1\n",
      "17  C3N-03086  6.254694e-08   6.254694e-08             0              1\n",
      "3   C3L-00017  4.262839e-03   4.262839e-03             0              1\n",
      "0   C3L-00017  4.262938e-03   4.262938e-03             0              1\n",
      "4   C3L-00017  4.265392e-03   4.265392e-03             0              1\n",
      "2   C3L-00017  4.267156e-03   4.267156e-03             0              1\n",
      "1   C3L-00017  4.267543e-03   4.267543e-03             0              1\n",
      "15  C3N-03086  1.093081e-02   1.093081e-02             0              1\n",
      "13  C3N-02944  1.457148e-02   1.457148e-02             0              1\n",
      "12  C3N-02944  1.457360e-02   1.457360e-02             0              1\n",
      "14  C3N-02944  1.457360e-02   1.457360e-02             0              1\n",
      "8   C3L-01328  1.980562e-02   1.980562e-02             0              1\n",
      "10  C3L-01328  1.980631e-02   1.980631e-02             0              1\n",
      "9   C3L-01328  1.980637e-02   1.980637e-02             0              1\n",
      "11  C3L-01328  2.039149e-02   2.039149e-02             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "7   C3L-00589   0.020595       0.020595             0              1\n",
      "6   C3L-00589   0.020594       0.020594             0              1\n",
      "5   C3L-00589   0.020591       0.020591             0              1\n",
      "11  C3L-01328   0.020391       0.020391             0              1\n",
      "9   C3L-01328   0.019806       0.019806             0              1\n",
      "10  C3L-01328   0.019806       0.019806             0              1\n",
      "8   C3L-01328   0.019806       0.019806             0              1\n",
      "14  C3N-02944   0.014574       0.014574             0              1\n",
      "12  C3N-02944   0.014574       0.014574             0              1\n",
      "13  C3N-02944   0.014571       0.014571             0              1\n",
      "15  C3N-03086   0.010931       0.010931             0              1\n",
      "1   C3L-00017   0.004268       0.004268             0              1\n",
      "2   C3L-00017   0.004267       0.004267             0              1\n",
      "4   C3L-00017   0.004265       0.004265             0              1\n",
      "0   C3L-00017   0.004263       0.004263             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed30/fold_4_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed30/fold_4_topk/topk_high_gradient.csv\n"
     ]
    }
   ],
   "source": [
    "folds_dir = \"./models/ckpts/CPTACPDA_trainmixed30_multival_Titan_MedImSight\"\n",
    "test_path = \"./data/processed/processed_CPTAC_PDA_survival/k=all.tsv\"\n",
    "ct_path = \"../MedImageInsights/embeddings_output_cptacpda_93\"\n",
    "wsi_path = \"../../TitanCPTACPDA/20x_512px_0px_overlap/slide_features_titan\"\n",
    "output_dir = \"./interpretability/interpretability_PDA_mixed30\"\n",
    "evaluate_and_log(folds_dir,ct_path,wsi_path,test_path,output_dir,batch_size=16)\n",
    "# Example usage\n",
    "for i in range(5):\n",
    "    csv_input = f\"./interpretability/interpretability_PDA_mixed30/fold_{i}_log.csv\"\n",
    "    find_topk_gradient_extremes(\n",
    "        csv_path=csv_input,\n",
    "        k=15,\n",
    "        output_dir=f\"./interpretability/interpretability_PDA_mixed30/fold_{i}_topk\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f00b78",
   "metadata": {},
   "source": [
    "## CPTAC-PDA Mixed 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b71e2204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3 ===\n",
      "\n",
      "=== Fold 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "2   C3L-04479   0.001864       0.001864             1              1\n",
      "1   C3L-04479   0.036011       0.036011             1              1\n",
      "5   C3N-02573   0.045232       0.045232             0              1\n",
      "4   C3N-02573   0.045249       0.045249             0              1\n",
      "3   C3N-02573   0.045285       0.045285             0              1\n",
      "10  C3N-03839   0.047283       0.047283             0              1\n",
      "12  C3N-03839   0.047340       0.047340             0              1\n",
      "11  C3N-03839   0.047428       0.047428             0              1\n",
      "9   C3N-03839   0.047582       0.047582             0              1\n",
      "0   C3L-02897   0.055466       0.055466             0              1\n",
      "6   C3N-02940   0.062714       0.062714             0              1\n",
      "8   C3N-02940   0.063409       0.063409             0              1\n",
      "7   C3N-02940   0.063509       0.063509             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "7   C3N-02940   0.063509       0.063509             0              1\n",
      "8   C3N-02940   0.063409       0.063409             0              1\n",
      "6   C3N-02940   0.062714       0.062714             0              1\n",
      "0   C3L-02897   0.055466       0.055466             0              1\n",
      "9   C3N-03839   0.047582       0.047582             0              1\n",
      "11  C3N-03839   0.047428       0.047428             0              1\n",
      "12  C3N-03839   0.047340       0.047340             0              1\n",
      "10  C3N-03839   0.047283       0.047283             0              1\n",
      "3   C3N-02573   0.045285       0.045285             0              1\n",
      "4   C3N-02573   0.045249       0.045249             0              1\n",
      "5   C3N-02573   0.045232       0.045232             0              1\n",
      "1   C3L-04479   0.036011       0.036011             1              1\n",
      "2   C3L-04479   0.001864       0.001864             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed15/fold_0_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed15/fold_0_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "9   C3L-04027   0.000000       0.000000             0              1\n",
      "16  C3N-02585   0.000000       0.000000             0              1\n",
      "15  C3N-02010   0.000000       0.000000             1              1\n",
      "14  C3N-02010   0.000000       0.000000             1              1\n",
      "13  C3N-01012   0.000000       0.000000             1              1\n",
      "12  C3L-04027   0.000000       0.000000             0              1\n",
      "11  C3L-04027   0.000000       0.000000             0              1\n",
      "10  C3L-04027   0.000000       0.000000             0              1\n",
      "17  C3N-02585   0.000000       0.000000             0              1\n",
      "18  C3N-02585   0.000000       0.000000             0              1\n",
      "7   C3L-04027   0.000000       0.000000             0              1\n",
      "8   C3L-04027   0.000000       0.000000             0              1\n",
      "2   C3L-03630   0.014625       0.014625             0              1\n",
      "6   C3L-04027   0.019031       0.019031             0              1\n",
      "5   C3L-04027   0.020581       0.020581             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0   C3L-03356   0.095126       0.095126             1              1\n",
      "4   C3L-03630   0.030446       0.030446             0              1\n",
      "3   C3L-03630   0.030444       0.030444             0              1\n",
      "1   C3L-03630   0.030439       0.030439             0              1\n",
      "5   C3L-04027   0.020581       0.020581             0              1\n",
      "6   C3L-04027   0.019031       0.019031             0              1\n",
      "2   C3L-03630   0.014625       0.014625             0              1\n",
      "8   C3L-04027   0.000000       0.000000             0              1\n",
      "7   C3L-04027   0.000000       0.000000             0              1\n",
      "18  C3N-02585   0.000000       0.000000             0              1\n",
      "17  C3N-02585   0.000000       0.000000             0              1\n",
      "10  C3L-04027   0.000000       0.000000             0              1\n",
      "11  C3L-04027   0.000000       0.000000             0              1\n",
      "12  C3L-04027   0.000000       0.000000             0              1\n",
      "13  C3N-01012   0.000000       0.000000             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed15/fold_1_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed15/fold_1_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "13  C3N-03840   0.000003       0.000003             0              1\n",
      "14  C3N-03840   0.000009       0.000009             0              1\n",
      "12  C3N-03840   0.000012       0.000012             0              1\n",
      "5   C3N-00198   0.002508       0.002508             1              1\n",
      "7   C3N-00198   0.002518       0.002518             1              1\n",
      "6   C3N-00198   0.002646       0.002646             1              1\n",
      "8   C3N-00198   0.005587       0.005587             1              1\n",
      "9   C3N-00198   0.007200       0.007200             1              1\n",
      "11  C3N-03006   0.011902       0.011902             0              1\n",
      "10  C3N-03006   0.011903       0.011903             0              1\n",
      "1   C3L-01031   0.031214       0.031214             0              1\n",
      "2   C3L-01031   0.031216       0.031216             0              1\n",
      "0   C3L-01031   0.031223       0.031223             0              1\n",
      "3   C3L-02109   0.032150       0.032150             1              1\n",
      "4   C3L-02109   0.032156       0.032156             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "4   C3L-02109   0.032156       0.032156             1              1\n",
      "3   C3L-02109   0.032150       0.032150             1              1\n",
      "0   C3L-01031   0.031223       0.031223             0              1\n",
      "2   C3L-01031   0.031216       0.031216             0              1\n",
      "1   C3L-01031   0.031214       0.031214             0              1\n",
      "10  C3N-03006   0.011903       0.011903             0              1\n",
      "11  C3N-03006   0.011902       0.011902             0              1\n",
      "9   C3N-00198   0.007200       0.007200             1              1\n",
      "8   C3N-00198   0.005587       0.005587             1              1\n",
      "6   C3N-00198   0.002646       0.002646             1              1\n",
      "7   C3N-00198   0.002518       0.002518             1              1\n",
      "5   C3N-00198   0.002508       0.002508             1              1\n",
      "12  C3N-03840   0.000012       0.000012             0              1\n",
      "14  C3N-03840   0.000009       0.000009             0              1\n",
      "13  C3N-03840   0.000003       0.000003             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed15/fold_2_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed15/fold_2_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0   C3L-01124        0.0            0.0             0              1\n",
      "1   C3L-01124        0.0            0.0             0              1\n",
      "2   C3L-01124        0.0            0.0             0              1\n",
      "3   C3L-02463        0.0            0.0             0              1\n",
      "4   C3L-02463        0.0            0.0             0              1\n",
      "5   C3L-02463        0.0            0.0             0              1\n",
      "6   C3L-02463        0.0            0.0             0              1\n",
      "7   C3L-02463        0.0            0.0             0              1\n",
      "8   C3L-02463        0.0            0.0             0              1\n",
      "9   C3L-03123        0.0            0.0             1              1\n",
      "10  C3L-03123        0.0            0.0             1              1\n",
      "11  C3N-03173        0.0            0.0             0              1\n",
      "12  C3N-03173        0.0            0.0             0              1\n",
      "13  C3N-03665        0.0            0.0             0              1\n",
      "14  C3N-03665        0.0            0.0             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "14  C3N-03665        0.0            0.0             0              1\n",
      "13  C3N-03665        0.0            0.0             0              1\n",
      "12  C3N-03173        0.0            0.0             0              1\n",
      "11  C3N-03173        0.0            0.0             0              1\n",
      "10  C3L-03123        0.0            0.0             1              1\n",
      "9   C3L-03123        0.0            0.0             1              1\n",
      "8   C3L-02463        0.0            0.0             0              1\n",
      "7   C3L-02463        0.0            0.0             0              1\n",
      "6   C3L-02463        0.0            0.0             0              1\n",
      "5   C3L-02463        0.0            0.0             0              1\n",
      "4   C3L-02463        0.0            0.0             0              1\n",
      "3   C3L-02463        0.0            0.0             0              1\n",
      "2   C3L-01124        0.0            0.0             0              1\n",
      "1   C3L-01124        0.0            0.0             0              1\n",
      "0   C3L-01124        0.0            0.0             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed15/fold_3_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed15/fold_3_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id     grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "17  C3N-03086  1.245739e-07   1.245739e-07             0              1\n",
      "16  C3N-03086  1.245739e-07   1.245739e-07             0              1\n",
      "1   C3L-00017  2.645434e-03   2.645434e-03             0              1\n",
      "2   C3L-00017  2.645444e-03   2.645444e-03             0              1\n",
      "3   C3L-00017  2.927110e-03   2.927110e-03             0              1\n",
      "0   C3L-00017  2.927596e-03   2.927596e-03             0              1\n",
      "4   C3L-00017  2.927762e-03   2.927762e-03             0              1\n",
      "15  C3N-03086  8.199172e-03   8.199172e-03             0              1\n",
      "12  C3N-02944  9.832833e-03   9.832833e-03             0              1\n",
      "14  C3N-02944  9.832930e-03   9.832930e-03             0              1\n",
      "13  C3N-02944  1.058094e-02   1.058094e-02             0              1\n",
      "11  C3L-01328  1.093730e-02   1.093730e-02             0              1\n",
      "7   C3L-00589  1.221267e-02   1.221267e-02             0              1\n",
      "9   C3L-01328  1.235773e-02   1.235773e-02             0              1\n",
      "10  C3L-01328  1.235780e-02   1.235780e-02             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "5   C3L-00589   0.012836       0.012836             0              1\n",
      "6   C3L-00589   0.012836       0.012836             0              1\n",
      "8   C3L-01328   0.012425       0.012425             0              1\n",
      "10  C3L-01328   0.012358       0.012358             0              1\n",
      "9   C3L-01328   0.012358       0.012358             0              1\n",
      "7   C3L-00589   0.012213       0.012213             0              1\n",
      "11  C3L-01328   0.010937       0.010937             0              1\n",
      "13  C3N-02944   0.010581       0.010581             0              1\n",
      "14  C3N-02944   0.009833       0.009833             0              1\n",
      "12  C3N-02944   0.009833       0.009833             0              1\n",
      "15  C3N-03086   0.008199       0.008199             0              1\n",
      "4   C3L-00017   0.002928       0.002928             0              1\n",
      "0   C3L-00017   0.002928       0.002928             0              1\n",
      "3   C3L-00017   0.002927       0.002927             0              1\n",
      "2   C3L-00017   0.002645       0.002645             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed15/fold_4_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed15/fold_4_topk/topk_high_gradient.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folds_dir = \"./models/ckpts/CPTACPDA_trainmixed15_multival_Titan_MedImSight\"\n",
    "test_path = \"./data/processed/processed_CPTAC_PDA_survival/k=all.tsv\"\n",
    "ct_path = \"../MedImageInsights/embeddings_output_cptacpda_93\"\n",
    "wsi_path = \"../../TitanCPTACPDA/20x_512px_0px_overlap/slide_features_titan\"\n",
    "output_dir = \"./interpretability/interpretability_PDA_mixed15\"\n",
    "evaluate_and_log(folds_dir,ct_path,wsi_path,test_path,output_dir,batch_size=16)\n",
    "for i in range(5):\n",
    "    csv_input = f\"./interpretability/interpretability_PDA_mixed15/fold_{i}_log.csv\"\n",
    "    find_topk_gradient_extremes(\n",
    "        csv_path=csv_input,\n",
    "        k=15,\n",
    "        output_dir=f\"./interpretability/interpretability_PDA_mixed15/fold_{i}_topk\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece50f2e",
   "metadata": {},
   "source": [
    "## CPTAC PDA mixed 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efda33e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3 ===\n",
      "\n",
      "=== Fold 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618112/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "2   C3L-04479   0.011065       0.011065             1              1\n",
      "1   C3L-04479   0.013125       0.013125             1              1\n",
      "9   C3N-03839   0.013275       0.013275             0              1\n",
      "11  C3N-03839   0.013275       0.013275             0              1\n",
      "12  C3N-03839   0.013275       0.013275             0              1\n",
      "10  C3N-03839   0.013275       0.013275             0              1\n",
      "8   C3N-02940   0.017700       0.017700             0              1\n",
      "7   C3N-02940   0.017700       0.017700             0              1\n",
      "6   C3N-02940   0.017701       0.017701             0              1\n",
      "3   C3N-02573   0.018294       0.018294             0              1\n",
      "4   C3N-02573   0.018294       0.018294             0              1\n",
      "5   C3N-02573   0.018294       0.018294             0              1\n",
      "0   C3L-02897   0.022016       0.022016             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0   C3L-02897   0.022016       0.022016             0              1\n",
      "5   C3N-02573   0.018294       0.018294             0              1\n",
      "4   C3N-02573   0.018294       0.018294             0              1\n",
      "3   C3N-02573   0.018294       0.018294             0              1\n",
      "6   C3N-02940   0.017701       0.017701             0              1\n",
      "7   C3N-02940   0.017700       0.017700             0              1\n",
      "8   C3N-02940   0.017700       0.017700             0              1\n",
      "10  C3N-03839   0.013275       0.013275             0              1\n",
      "12  C3N-03839   0.013275       0.013275             0              1\n",
      "11  C3N-03839   0.013275       0.013275             0              1\n",
      "9   C3N-03839   0.013275       0.013275             0              1\n",
      "1   C3L-04479   0.013125       0.013125             1              1\n",
      "2   C3L-04479   0.011065       0.011065             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed5/fold_0_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed5/fold_0_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "6   C3L-04027   0.012811       0.012811             0              1\n",
      "5   C3L-04027   0.012813       0.012813             0              1\n",
      "7   C3L-04027   0.012829       0.012829             0              1\n",
      "18  C3N-02585   0.018468       0.018468             0              1\n",
      "17  C3N-02585   0.018676       0.018676             0              1\n",
      "16  C3N-02585   0.018732       0.018732             0              1\n",
      "13  C3N-01012   0.019751       0.019751             1              1\n",
      "15  C3N-02010   0.020441       0.020441             1              1\n",
      "14  C3N-02010   0.021273       0.021273             1              1\n",
      "3   C3L-03630   0.022912       0.022912             0              1\n",
      "1   C3L-03630   0.022924       0.022924             0              1\n",
      "4   C3L-03630   0.022937       0.022937             0              1\n",
      "2   C3L-03630   0.022969       0.022969             0              1\n",
      "10  C3L-04027   0.023850       0.023850             0              1\n",
      "8   C3L-04027   0.023903       0.023903             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0   C3L-03356   0.054832       0.054832             1              1\n",
      "12  C3L-04027   0.023955       0.023955             0              1\n",
      "11  C3L-04027   0.023935       0.023935             0              1\n",
      "9   C3L-04027   0.023909       0.023909             0              1\n",
      "8   C3L-04027   0.023903       0.023903             0              1\n",
      "10  C3L-04027   0.023850       0.023850             0              1\n",
      "2   C3L-03630   0.022969       0.022969             0              1\n",
      "4   C3L-03630   0.022937       0.022937             0              1\n",
      "1   C3L-03630   0.022924       0.022924             0              1\n",
      "3   C3L-03630   0.022912       0.022912             0              1\n",
      "14  C3N-02010   0.021273       0.021273             1              1\n",
      "15  C3N-02010   0.020441       0.020441             1              1\n",
      "13  C3N-01012   0.019751       0.019751             1              1\n",
      "16  C3N-02585   0.018732       0.018732             0              1\n",
      "17  C3N-02585   0.018676       0.018676             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed5/fold_1_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed5/fold_1_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "14  C3N-03840   0.000116       0.000116             0              1\n",
      "13  C3N-03840   0.000117       0.000117             0              1\n",
      "12  C3N-03840   0.000233       0.000233             0              1\n",
      "8   C3N-00198   0.001016       0.001016             1              1\n",
      "7   C3N-00198   0.002805       0.002805             1              1\n",
      "5   C3N-00198   0.003807       0.003807             1              1\n",
      "9   C3N-00198   0.005165       0.005165             1              1\n",
      "4   C3L-02109   0.006397       0.006397             1              1\n",
      "6   C3N-00198   0.006825       0.006825             1              1\n",
      "11  C3N-03006   0.007113       0.007113             0              1\n",
      "10  C3N-03006   0.007118       0.007118             0              1\n",
      "2   C3L-01031   0.022152       0.022152             0              1\n",
      "0   C3L-01031   0.022191       0.022191             0              1\n",
      "1   C3L-01031   0.022193       0.022193             0              1\n",
      "3   C3L-02109   0.027441       0.027441             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "3   C3L-02109   0.027441       0.027441             1              1\n",
      "1   C3L-01031   0.022193       0.022193             0              1\n",
      "0   C3L-01031   0.022191       0.022191             0              1\n",
      "2   C3L-01031   0.022152       0.022152             0              1\n",
      "10  C3N-03006   0.007118       0.007118             0              1\n",
      "11  C3N-03006   0.007113       0.007113             0              1\n",
      "6   C3N-00198   0.006825       0.006825             1              1\n",
      "4   C3L-02109   0.006397       0.006397             1              1\n",
      "9   C3N-00198   0.005165       0.005165             1              1\n",
      "5   C3N-00198   0.003807       0.003807             1              1\n",
      "7   C3N-00198   0.002805       0.002805             1              1\n",
      "8   C3N-00198   0.001016       0.001016             1              1\n",
      "12  C3N-03840   0.000233       0.000233             0              1\n",
      "13  C3N-03840   0.000117       0.000117             0              1\n",
      "14  C3N-03840   0.000116       0.000116             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed5/fold_2_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed5/fold_2_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0   C3L-01124        0.0            0.0             0              1\n",
      "1   C3L-01124        0.0            0.0             0              1\n",
      "2   C3L-01124        0.0            0.0             0              1\n",
      "3   C3L-02463        0.0            0.0             0              1\n",
      "4   C3L-02463        0.0            0.0             0              1\n",
      "5   C3L-02463        0.0            0.0             0              1\n",
      "6   C3L-02463        0.0            0.0             0              1\n",
      "7   C3L-02463        0.0            0.0             0              1\n",
      "8   C3L-02463        0.0            0.0             0              1\n",
      "9   C3L-03123        0.0            0.0             1              1\n",
      "10  C3L-03123        0.0            0.0             1              1\n",
      "11  C3N-03173        0.0            0.0             0              1\n",
      "12  C3N-03173        0.0            0.0             0              1\n",
      "13  C3N-03665        0.0            0.0             0              1\n",
      "14  C3N-03665        0.0            0.0             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "14  C3N-03665        0.0            0.0             0              1\n",
      "13  C3N-03665        0.0            0.0             0              1\n",
      "12  C3N-03173        0.0            0.0             0              1\n",
      "11  C3N-03173        0.0            0.0             0              1\n",
      "10  C3L-03123        0.0            0.0             1              1\n",
      "9   C3L-03123        0.0            0.0             1              1\n",
      "8   C3L-02463        0.0            0.0             0              1\n",
      "7   C3L-02463        0.0            0.0             0              1\n",
      "6   C3L-02463        0.0            0.0             0              1\n",
      "5   C3L-02463        0.0            0.0             0              1\n",
      "4   C3L-02463        0.0            0.0             0              1\n",
      "3   C3L-02463        0.0            0.0             0              1\n",
      "2   C3L-01124        0.0            0.0             0              1\n",
      "1   C3L-01124        0.0            0.0             0              1\n",
      "0   C3L-01124        0.0            0.0             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed5/fold_3_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed5/fold_3_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "17  C3N-03086   0.000000       0.000000             0              1\n",
      "16  C3N-03086   0.000000       0.000000             0              1\n",
      "1   C3L-00017   0.001028       0.001028             0              1\n",
      "2   C3L-00017   0.001028       0.001028             0              1\n",
      "0   C3L-00017   0.001028       0.001028             0              1\n",
      "4   C3L-00017   0.001028       0.001028             0              1\n",
      "3   C3L-00017   0.001028       0.001028             0              1\n",
      "15  C3N-03086   0.002888       0.002888             0              1\n",
      "12  C3N-02944   0.003851       0.003851             0              1\n",
      "14  C3N-02944   0.003851       0.003851             0              1\n",
      "13  C3N-02944   0.003851       0.003851             0              1\n",
      "9   C3L-01328   0.004638       0.004638             0              1\n",
      "10  C3L-01328   0.004638       0.004638             0              1\n",
      "8   C3L-01328   0.004638       0.004638             0              1\n",
      "7   C3L-00589   0.004748       0.004748             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "   patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "11  C3L-01328   0.004990       0.004990             0              1\n",
      "6   C3L-00589   0.004748       0.004748             0              1\n",
      "5   C3L-00589   0.004748       0.004748             0              1\n",
      "7   C3L-00589   0.004748       0.004748             0              1\n",
      "8   C3L-01328   0.004638       0.004638             0              1\n",
      "10  C3L-01328   0.004638       0.004638             0              1\n",
      "9   C3L-01328   0.004638       0.004638             0              1\n",
      "13  C3N-02944   0.003851       0.003851             0              1\n",
      "14  C3N-02944   0.003851       0.003851             0              1\n",
      "12  C3N-02944   0.003851       0.003851             0              1\n",
      "15  C3N-03086   0.002888       0.002888             0              1\n",
      "3   C3L-00017   0.001028       0.001028             0              1\n",
      "4   C3L-00017   0.001028       0.001028             0              1\n",
      "0   C3L-00017   0.001028       0.001028             0              1\n",
      "2   C3L-00017   0.001028       0.001028             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed5/fold_4_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed5/fold_4_topk/topk_high_gradient.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folds_dir = \"./models/ckpts/CPTACPDA_trainmixed5_multival_Titan_MedImSight\"\n",
    "test_path = \"./data/processed/processed_CPTAC_PDA_survival/k=all.tsv\"\n",
    "ct_path = \"../MedImageInsights/embeddings_output_cptacpda_93\"\n",
    "wsi_path = \"../../TitanCPTACPDA/20x_512px_0px_overlap/slide_features_titan\"\n",
    "output_dir = \"./interpretability/interpretability_PDA_mixed5\"\n",
    "\n",
    "evaluate_and_log(folds_dir,ct_path,wsi_path,test_path,output_dir,batch_size=16)\n",
    "for i in range(5):\n",
    "    csv_input = f\"./interpretability/interpretability_PDA_mixed5/fold_{i}_log.csv\"\n",
    "    find_topk_gradient_extremes(\n",
    "        csv_path=csv_input,\n",
    "        k=15,\n",
    "        output_dir=f\"./interpretability/interpretability_PDA_mixed5/fold_{i}_topk\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41616de2",
   "metadata": {},
   "source": [
    "## CPTAC UCEC 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a09b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 2 ===\n",
      "\n",
      "=== Fold 3 ===\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-02631   0.024910       0.024910             1              1\n",
      "1  C3N-02631   0.025809       0.025809             1              1\n",
      "2  C3N-02631   0.059789       0.059789             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "2  C3N-02631   0.059789       0.059789             1              1\n",
      "1  C3N-02631   0.025809       0.025809             1              1\n",
      "0  C3N-02631   0.024910       0.024910             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed5/fold_0_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed5/fold_0_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1  C3N-02678    0.21507        0.21507             1              1\n",
      "0  C3N-02678    0.22254        0.22254             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-02678    0.22254        0.22254             1              1\n",
      "1  C3N-02678    0.21507        0.21507             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed5/fold_1_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed5/fold_1_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-01877        0.0            0.0             1              1\n",
      "1  C3N-01877        0.0            0.0             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1  C3N-01877        0.0            0.0             1              1\n",
      "0  C3N-01877        0.0            0.0             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed5/fold_2_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed5/fold_2_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-02639        0.0            0.0             1              1\n",
      "1  C3N-02639        0.0            0.0             1              1\n",
      "2  C3N-01003        0.0            0.0             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "2  C3N-01003        0.0            0.0             1              1\n",
      "1  C3N-02639        0.0            0.0             1              1\n",
      "0  C3N-02639        0.0            0.0             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed5/fold_3_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed5/fold_3_topk/topk_high_gradient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    }
   ],
   "source": [
    "folds_dir = \"./models/ckpts/CPTAC_UCEC_titan_medimsight_trainmixed5\"\n",
    "ct_path= \"../MedImageInsights/embeddings_cptacucec\"\n",
    "wsi_path= \"../../trident_processed_UCEC_titan/20x_512px_0px_overlap/slide_features_titan\"\n",
    "test_path =  \"./data/processed/processed_CPTACUCEC_survival/k=all.tsv\"\n",
    "output_dir = \"./interpretability/interpretability_UCEC_mixed5\"\n",
    "\n",
    "evaluate_and_log(folds_dir,ct_path,wsi_path,test_path,output_dir,batch_size=16, n_folds=4)\n",
    "for i in range(4):\n",
    "    csv_input = f\"./interpretability/interpretability_UCEC_mixed5/fold_{i}_log.csv\"\n",
    "    find_topk_gradient_extremes(\n",
    "        csv_path=csv_input,\n",
    "        k=15,\n",
    "        output_dir=f\"./interpretability/interpretability_UCEC_mixed5/fold_{i}_topk\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51956999",
   "metadata": {},
   "source": [
    "## CPTAC UCEC 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f34bc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3 ===\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "2  C3N-02631   0.000066       0.000066             1              1\n",
      "0  C3N-02631   0.003875       0.003875             1              1\n",
      "1  C3N-02631   0.057459       0.057459             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1  C3N-02631   0.057459       0.057459             1              1\n",
      "0  C3N-02631   0.003875       0.003875             1              1\n",
      "2  C3N-02631   0.000066       0.000066             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed15/fold_0_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed15/fold_0_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1  C3N-02678   0.008612       0.008612             1              1\n",
      "0  C3N-02678   0.008679       0.008679             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-02678   0.008679       0.008679             1              1\n",
      "1  C3N-02678   0.008612       0.008612             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed15/fold_1_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed15/fold_1_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-01877   0.035775       0.035775             1              1\n",
      "1  C3N-01877   0.053197       0.053197             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1  C3N-01877   0.053197       0.053197             1              1\n",
      "0  C3N-01877   0.035775       0.035775             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed15/fold_2_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed15/fold_2_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "2  C3N-01003   0.000662       0.000662             1              1\n",
      "1  C3N-02639   0.080682       0.080682             1              1\n",
      "0  C3N-02639   0.085217       0.085217             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-02639   0.085217       0.085217             1              1\n",
      "1  C3N-02639   0.080682       0.080682             1              1\n",
      "2  C3N-01003   0.000662       0.000662             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed15/fold_3_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed15/fold_3_topk/topk_high_gradient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    }
   ],
   "source": [
    "folds_dir = \"./models/ckpts/CPTAC_UCEC_titan_medimsight_trainmixed15\"\n",
    "ct_path= \"../MedImageInsights/embeddings_cptacucec\"\n",
    "wsi_path= \"../../trident_processed_UCEC_titan/20x_512px_0px_overlap/slide_features_titan\"\n",
    "test_path =  \"./data/processed/processed_CPTACUCEC_survival/k=all.tsv\"\n",
    "output_dir = \"./interpretability/interpretability_UCEC_mixed15\"\n",
    "\n",
    "evaluate_and_log(folds_dir,ct_path,wsi_path,test_path,output_dir,batch_size=16, n_folds=4)\n",
    "for i in range(4):\n",
    "    csv_input = f\"./interpretability/interpretability_UCEC_mixed15/fold_{i}_log.csv\"\n",
    "    find_topk_gradient_extremes(\n",
    "        csv_path=csv_input,\n",
    "        k=15,\n",
    "        output_dir=f\"./interpretability/interpretability_UCEC_mixed15/fold_{i}_topk\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65c024d",
   "metadata": {},
   "source": [
    "## CPTAC UCEC 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e3a607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3 ===\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1  C3N-02631   0.042108       0.042108             1              1\n",
      "0  C3N-02631   0.046808       0.046808             1              1\n",
      "2  C3N-02631   0.129161       0.129161             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "2  C3N-02631   0.129161       0.129161             1              1\n",
      "0  C3N-02631   0.046808       0.046808             1              1\n",
      "1  C3N-02631   0.042108       0.042108             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed30/fold_0_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed30/fold_0_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-02678   0.010099       0.010099             1              1\n",
      "1  C3N-02678   0.011291       0.011291             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1  C3N-02678   0.011291       0.011291             1              1\n",
      "0  C3N-02678   0.010099       0.010099             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed30/fold_1_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed30/fold_1_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-01877   0.001720       0.001720             1              1\n",
      "1  C3N-01877   0.004337       0.004337             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1  C3N-01877   0.004337       0.004337             1              1\n",
      "0  C3N-01877   0.001720       0.001720             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed30/fold_2_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed30/fold_2_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-02639        0.0            0.0             1              1\n",
      "1  C3N-02639        0.0            0.0             1              1\n",
      "2  C3N-01003        0.0            0.0             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "2  C3N-01003        0.0            0.0             1              1\n",
      "1  C3N-02639        0.0            0.0             1              1\n",
      "0  C3N-02639        0.0            0.0             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed30/fold_3_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed30/fold_3_topk/topk_high_gradient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    }
   ],
   "source": [
    "folds_dir = \"./models/ckpts/CPTAC_UCEC_titan_medimsight_trainmixed30\"\n",
    "ct_path= \"../MedImageInsights/embeddings_cptacucec\"\n",
    "wsi_path= \"../../trident_processed_UCEC_titan/20x_512px_0px_overlap/slide_features_titan\"\n",
    "test_path =  \"./data/processed/processed_CPTACUCEC_survival/k=all.tsv\"\n",
    "output_dir = \"./interpretability/interpretability_UCEC_mixed30\"\n",
    "\n",
    "evaluate_and_log(folds_dir,ct_path,wsi_path,test_path,output_dir,batch_size=16, n_folds=4)\n",
    "for i in range(4):\n",
    "    csv_input = f\"./interpretability/interpretability_UCEC_mixed30/fold_{i}_log.csv\"\n",
    "    find_topk_gradient_extremes(\n",
    "        csv_path=csv_input,\n",
    "        k=15,\n",
    "        output_dir=f\"./interpretability/interpretability_UCEC_mixed30/fold_{i}_topk\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf4e94",
   "metadata": {},
   "source": [
    "## CPTAC UCEC 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5363406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 0 ===\n",
      "\n",
      "=== Fold 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 2 ===\n",
      "\n",
      "=== Fold 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n",
      "/tmp/ipykernel_3618233/744619559.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1  C3N-02631   0.028265       0.028265             1              1\n",
      "0  C3N-02631   0.028285       0.028285             1              1\n",
      "2  C3N-02631   0.054864       0.054864             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "2  C3N-02631   0.054864       0.054864             1              1\n",
      "0  C3N-02631   0.028285       0.028285             1              1\n",
      "1  C3N-02631   0.028265       0.028265             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed50/fold_0_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed50/fold_0_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-02678        0.0            0.0             1              1\n",
      "1  C3N-02678        0.0            0.0             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1  C3N-02678        0.0            0.0             1              1\n",
      "0  C3N-02678        0.0            0.0             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed50/fold_1_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed50/fold_1_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "1  C3N-01877   0.005101       0.005101             1              1\n",
      "0  C3N-01877   0.005186       0.005186             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-01877   0.005186       0.005186             1              1\n",
      "1  C3N-01877   0.005101       0.005101             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed50/fold_2_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed50/fold_2_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0  C3N-02639        0.0            0.0             1              1\n",
      "1  C3N-02639        0.0            0.0             1              1\n",
      "2  C3N-01003        0.0            0.0             1              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "  patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "2  C3N-01003        0.0            0.0             1              1\n",
      "1  C3N-02639        0.0            0.0             1              1\n",
      "0  C3N-02639        0.0            0.0             1              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_UCEC_mixed50/fold_3_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_UCEC_mixed50/fold_3_topk/topk_high_gradient.csv\n"
     ]
    }
   ],
   "source": [
    "folds_dir = \"./models/ckpts/CPTACUCEC_trainmixed50_multival_Titan_MedImSight_fullepochs\"\n",
    "ct_path = \"../MedImageInsights/embeddings_cptacucec\"\n",
    "wsi_path = \"../../trident_processed_UCEC_titan/20x_512px_0px_overlap/slide_features_titan\"\n",
    "test_path = \"./data/processed/processed_CPTACUCEC_survival/k=all.tsv\"\n",
    "output_dir = \"./interpretability/interpretability_UCEC_mixed50\"\n",
    "\n",
    "evaluate_and_log(folds_dir,ct_path,wsi_path,test_path,output_dir,batch_size=16, n_folds=4)\n",
    "for i in range(4):\n",
    "    csv_input = f\"./interpretability/interpretability_UCEC_mixed50/fold_{i}_log.csv\"\n",
    "    find_topk_gradient_extremes(\n",
    "        csv_path=csv_input,\n",
    "        k=15,\n",
    "        output_dir=f\"./interpretability/interpretability_UCEC_mixed50/fold_{i}_topk\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e82612",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a76b90",
   "metadata": {},
   "source": [
    "## CPTAC PDA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf3b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_and_log(folds_dir, ct_path, wsi_path, test_path, output_dir, batch_size=16, n_folds=5):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        print(f\"\\n=== Fold {fold} ===\")\n",
    "        model = MADPENetNoBackbonesSurv(\n",
    "            rad_input_dim=1024, histo_input_dim=768,\n",
    "            inter_dim=256, token_dim=256, dim_hider=256\n",
    "        )\n",
    "        model.eval()\n",
    "\n",
    "        # Load checkpoint\n",
    "        fold_dir = os.path.join(folds_dir, f\"fold_{fold}\")\n",
    "        model_subdir = next(d for d in os.listdir(fold_dir)\n",
    "                            if os.path.isdir(os.path.join(fold_dir, d)))\n",
    "        model_file = next(f for f in os.listdir(os.path.join(fold_dir, model_subdir))\n",
    "                          if f.endswith(\"mixed_missing.pth\"))\n",
    "        checkpoint = torch.load(\n",
    "            os.path.join(fold_dir, model_subdir, model_file), map_location=\"cpu\"\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        dataset = MultimodalCTWSIDatasetSurv(\n",
    "            fold=0,\n",
    "            split=\"train\",\n",
    "            ct_path=ct_path,\n",
    "            wsi_path=wsi_path,\n",
    "            labels_splits_path=test_path,\n",
    "            missing_modality_prob=0.0,\n",
    "            require_both_modalities=False,\n",
    "            pairing_mode=\"one_to_one\",\n",
    "            allow_repeats=True,\n",
    "            pairs_per_patient=None,\n",
    "            missing_modality=\"wsi\"\n",
    "        )\n",
    "\n",
    "        loader = DataLoader(dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=0)\n",
    "\n",
    "        # CSV Logger\n",
    "        log_file = os.path.join(output_dir, f\"fold_{fold}_log.csv\")\n",
    "        fold_tensor_dir = os.path.join(output_dir, f\"fold_{fold}\")\n",
    "        os.makedirs(fold_tensor_dir, exist_ok=True)\n",
    "\n",
    "        with open(log_file, \"w\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([\n",
    "                \"patient_id\", \"ct_path\", \"wsi_path\",\n",
    "                \"ct_available\", \"wsi_available\",\n",
    "                \"hazard_score\", \"survtime\", \"censor\",\n",
    "                \"grad_norm\", \"curvature\",\n",
    "                \"fused_path\", \"pe_path\", \"hazard_tensor_path\"\n",
    "            ])\n",
    "\n",
    "            sample_counter = 0\n",
    "            for batch in loader:\n",
    "                # ensure floats\n",
    "                for k, v in batch.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        batch[k] = v.float()\n",
    "\n",
    "                with torch.enable_grad():\n",
    "                    for v in batch.values():\n",
    "                        if isinstance(v, torch.Tensor):\n",
    "                            v.requires_grad = True\n",
    "\n",
    "                    outputs = model(\n",
    "                        batch[\"ct_feature\"],\n",
    "                        batch[\"wsi_feature\"],\n",
    "                        modality_flag=batch[\"modality_mask\"],\n",
    "                        output_layers=[\"hazard\", \"fused_features\", \"positional_embeddings\"]\n",
    "                    )\n",
    "                    hazard = outputs[\"hazard\"].squeeze(1)  # [B]\n",
    "                    fused_features = outputs[\"fused_features\"]    # [B, D]\n",
    "                    pos_emb = outputs[\"positional_embeddings\"]    # [B, D]\n",
    "\n",
    "                    grad_norms, curvatures = compute_grad_and_curvature(\n",
    "                        fused_features, hazard,\n",
    "                        batch[\"survtime\"], batch[\"censor\"]\n",
    "                    )\n",
    "\n",
    "                # save per-sample\n",
    "                B = hazard.size(0)\n",
    "                for j in range(B):\n",
    "                    sample_id = f\"sample_{sample_counter:06d}\"\n",
    "                    fused_path = os.path.join(fold_tensor_dir, f\"{sample_id}_fused.npy\")\n",
    "                    pe_path = os.path.join(fold_tensor_dir, f\"{sample_id}_pe.npy\")\n",
    "                    hazard_path = os.path.join(fold_tensor_dir, f\"{sample_id}_hazard.npy\")\n",
    "\n",
    "                    np.save(fused_path, fused_features[j].detach().cpu().numpy())\n",
    "                    np.save(pe_path, pos_emb[j].detach().cpu().numpy())\n",
    "                    np.save(hazard_path, hazard[j].detach().cpu().numpy())\n",
    "\n",
    "                    ct_flag = int(batch[\"modality_mask\"][j, 0].item())\n",
    "                    wsi_flag = int(batch[\"modality_mask\"][j, 1].item())\n",
    "                    if batch[\"censor\"][j].item()==0: continue\n",
    "                    writer.writerow([\n",
    "                        batch[\"patient_id\"][j],\n",
    "                        dataset.samples[sample_counter][\"ct_path\"],\n",
    "                        dataset.samples[sample_counter][\"wsi_feature\"],\n",
    "                        ct_flag, wsi_flag,\n",
    "                        hazard[j].item(),\n",
    "                        batch[\"survtime\"][j].item(),\n",
    "                        batch[\"censor\"][j].item(),\n",
    "                        grad_norms[j], curvatures[j],\n",
    "                        fused_path, pe_path, hazard_path\n",
    "                    ])\n",
    "\n",
    "                    sample_counter += 1\n",
    "                    \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "def find_topk_gradient_extremes(\n",
    "    csv_path: str,\n",
    "    k: int = 10,\n",
    "    output_dir: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds top-k highest and lowest |gradient norm| samples from a CSV log.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to fold_X_log.csv generated during eval.\n",
    "        k (int): Number of top and bottom samples to retrieve.\n",
    "        output_dir (str): Optional folder to save CSVs. If None, only prints results.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if \"grad_norm\" not in df.columns:\n",
    "        raise ValueError(\"The CSV does not contain 'grad_norm' column.\")\n",
    "\n",
    "    # Compute absolute gradient norms\n",
    "    df[\"abs_grad_norm\"] = df[\"grad_norm\"].abs()\n",
    "\n",
    "    # Sort by absolute gradient norm\n",
    "    df_sorted = df.sort_values(by=\"abs_grad_norm\", ascending=True)\n",
    "\n",
    "    topk_low = df_sorted.head(k).copy()\n",
    "    topk_high = df_sorted.tail(k).copy()[::-1]  # High to low\n",
    "\n",
    "    print(\"\\nüîπ Top-k LOW |Gradient Norm| Samples:\")\n",
    "    print(topk_low[[\"patient_id\", \"grad_norm\", \"abs_grad_norm\", \"ct_available\", \"wsi_available\"]])\n",
    "\n",
    "    print(\"\\nüî∏ Top-k HIGH |Gradient Norm| Samples:\")\n",
    "    print(topk_high[[\"patient_id\", \"grad_norm\", \"abs_grad_norm\", \"ct_available\", \"wsi_available\"]])\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        low_path = os.path.join(output_dir, \"topk_low_gradient.csv\")\n",
    "        high_path = os.path.join(output_dir, \"topk_high_gradient.csv\")\n",
    "        topk_low.to_csv(low_path, index=False)\n",
    "        topk_high.to_csv(high_path, index=False)\n",
    "        print(f\"\\nüìÅ Saved to:\\n  {low_path}\\n  {high_path}\")\n",
    "\n",
    "    return topk_low, topk_high\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "SEED = 0\n",
    "\n",
    "def set_global_seed(seed=SEED):\n",
    "    \"\"\"\n",
    "    Set a global seed for reproducibility across different libraries and random number generators.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed value to be used\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_global_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "871f7286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3624295/1271137764.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3624295/1271137764.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3624295/1271137764.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3624295/1271137764.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3624295/1271137764.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "    patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "99   C3N-02768   0.000245       0.000245             0              1\n",
      "98   C3N-02768   0.000246       0.000246             0              1\n",
      "97   C3N-02768   0.000253       0.000253             0              1\n",
      "161  C3N-03190   0.000846       0.000846             0              1\n",
      "162  C3N-03190   0.000853       0.000853             0              1\n",
      "163  C3N-03190   0.000855       0.000855             0              1\n",
      "191  C3N-01379   0.001462       0.001462             0              1\n",
      "192  C3N-01379   0.001470       0.001470             0              1\n",
      "193  C3N-01379   0.001484       0.001484             0              1\n",
      "108  C3N-01168   0.005592       0.005592             0              1\n",
      "109  C3N-01168   0.005593       0.005593             0              1\n",
      "146  C3L-01158   0.005970       0.005970             0              1\n",
      "166  C3N-03086   0.005977       0.005977             0              1\n",
      "165  C3N-03086   0.005978       0.005978             0              1\n",
      "147  C3L-01158   0.005982       0.005982             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "    patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "14   C3N-01716   0.091586       0.091586             1              0\n",
      "15   C3N-01716   0.091155       0.091155             1              0\n",
      "106  C3L-01637   0.070939       0.070939             0              1\n",
      "107  C3L-01637   0.070926       0.070926             0              1\n",
      "134  C3N-00516   0.069489       0.069489             0              1\n",
      "133  C3N-00516   0.069488       0.069488             0              1\n",
      "95   C3L-01054   0.067221       0.067221             0              1\n",
      "96   C3L-01054   0.067219       0.067219             0              1\n",
      "94   C3L-01054   0.067197       0.067197             0              1\n",
      "75   C3N-02940   0.063956       0.063956             0              1\n",
      "76   C3N-02940   0.063956       0.063956             0              1\n",
      "74   C3N-02940   0.063917       0.063917             0              1\n",
      "58   C3N-03666   0.063618       0.063618             0              1\n",
      "135  C3N-00516   0.062237       0.062237             0              1\n",
      "190  C3N-01900   0.061396       0.061396             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed50TEST/fold_0_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed50TEST/fold_0_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "    patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0    C3L-04473        0.0            0.0             0              1\n",
      "126  C3L-00102        0.0            0.0             0              1\n",
      "127  C3L-00102        0.0            0.0             0              1\n",
      "128  C3N-04282        0.0            0.0             0              1\n",
      "129  C3N-04282        0.0            0.0             0              1\n",
      "130  C3N-04119        0.0            0.0             0              1\n",
      "131  C3N-04119        0.0            0.0             0              1\n",
      "132  C3N-04119        0.0            0.0             0              1\n",
      "133  C3N-00516        0.0            0.0             0              1\n",
      "134  C3N-00516        0.0            0.0             0              1\n",
      "135  C3N-00516        0.0            0.0             0              1\n",
      "136  C3L-01662        0.0            0.0             0              1\n",
      "137  C3L-01662        0.0            0.0             0              1\n",
      "138  C3L-01662        0.0            0.0             0              1\n",
      "139  C3L-01662        0.0            0.0             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "    patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "198  C3N-03778        0.0            0.0             0              1\n",
      "73   C3N-04126        0.0            0.0             0              1\n",
      "71   C3N-04126        0.0            0.0             0              1\n",
      "70   C3L-02701        0.0            0.0             0              1\n",
      "69   C3L-02701        0.0            0.0             0              1\n",
      "68   C3L-02701        0.0            0.0             0              1\n",
      "67   C3L-02701        0.0            0.0             0              1\n",
      "66   C3L-02701        0.0            0.0             0              1\n",
      "65   C3L-02701        0.0            0.0             0              1\n",
      "64   C3L-02701        0.0            0.0             0              1\n",
      "63   C3L-02701        0.0            0.0             0              1\n",
      "62   C3L-04072        0.0            0.0             0              1\n",
      "61   C3L-04072        0.0            0.0             0              1\n",
      "60   C3N-03439        0.0            0.0             0              1\n",
      "59   C3N-03439        0.0            0.0             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed50TEST/fold_1_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed50TEST/fold_1_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "    patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0    C3L-04473        0.0            0.0             0              1\n",
      "126  C3L-00102        0.0            0.0             0              1\n",
      "127  C3L-00102        0.0            0.0             0              1\n",
      "128  C3N-04282        0.0            0.0             0              1\n",
      "129  C3N-04282        0.0            0.0             0              1\n",
      "130  C3N-04119        0.0            0.0             0              1\n",
      "131  C3N-04119        0.0            0.0             0              1\n",
      "132  C3N-04119        0.0            0.0             0              1\n",
      "133  C3N-00516        0.0            0.0             0              1\n",
      "134  C3N-00516        0.0            0.0             0              1\n",
      "135  C3N-00516        0.0            0.0             0              1\n",
      "136  C3L-01662        0.0            0.0             0              1\n",
      "137  C3L-01662        0.0            0.0             0              1\n",
      "138  C3L-01662        0.0            0.0             0              1\n",
      "139  C3L-01662        0.0            0.0             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "    patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "13   C3N-01716   0.064586       0.064586             1              0\n",
      "15   C3N-01716   0.015250       0.015250             1              0\n",
      "198  C3N-03778   0.000000       0.000000             0              1\n",
      "74   C3N-02940   0.000000       0.000000             0              1\n",
      "72   C3N-04126   0.000000       0.000000             0              1\n",
      "71   C3N-04126   0.000000       0.000000             0              1\n",
      "70   C3L-02701   0.000000       0.000000             0              1\n",
      "69   C3L-02701   0.000000       0.000000             0              1\n",
      "68   C3L-02701   0.000000       0.000000             0              1\n",
      "67   C3L-02701   0.000000       0.000000             0              1\n",
      "66   C3L-02701   0.000000       0.000000             0              1\n",
      "65   C3L-02701   0.000000       0.000000             0              1\n",
      "64   C3L-02701   0.000000       0.000000             0              1\n",
      "63   C3L-02701   0.000000       0.000000             0              1\n",
      "62   C3L-04072   0.000000       0.000000             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed50TEST/fold_2_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed50TEST/fold_2_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "    patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "97   C3N-02768   0.000017       0.000017             0              1\n",
      "99   C3N-02768   0.000017       0.000017             0              1\n",
      "98   C3N-02768   0.000017       0.000017             0              1\n",
      "163  C3N-03190   0.000059       0.000059             0              1\n",
      "162  C3N-03190   0.000059       0.000059             0              1\n",
      "161  C3N-03190   0.000059       0.000059             0              1\n",
      "193  C3N-01379   0.000101       0.000101             0              1\n",
      "192  C3N-01379   0.000101       0.000101             0              1\n",
      "191  C3N-01379   0.000101       0.000101             0              1\n",
      "109  C3N-01168   0.000385       0.000385             0              1\n",
      "108  C3N-01168   0.000385       0.000385             0              1\n",
      "164  C3N-03086   0.000411       0.000411             0              1\n",
      "148  C3L-01158   0.000411       0.000411             0              1\n",
      "147  C3L-01158   0.000411       0.000411             0              1\n",
      "165  C3N-03086   0.000411       0.000411             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "    patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "15   C3N-01716   0.009583       0.009583             1              0\n",
      "13   C3N-01716   0.009579       0.009579             1              0\n",
      "14   C3N-01716   0.009576       0.009576             1              0\n",
      "107  C3L-01637   0.004880       0.004880             0              1\n",
      "106  C3L-01637   0.004879       0.004879             0              1\n",
      "134  C3N-00516   0.004780       0.004780             0              1\n",
      "133  C3N-00516   0.004780       0.004780             0              1\n",
      "94   C3L-01054   0.004624       0.004624             0              1\n",
      "96   C3L-01054   0.004624       0.004624             0              1\n",
      "95   C3L-01054   0.004624       0.004624             0              1\n",
      "74   C3N-02940   0.004399       0.004399             0              1\n",
      "76   C3N-02940   0.004399       0.004399             0              1\n",
      "75   C3N-02940   0.004399       0.004399             0              1\n",
      "58   C3N-03666   0.004374       0.004374             0              1\n",
      "135  C3N-00516   0.004281       0.004281             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed50TEST/fold_3_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed50TEST/fold_3_topk/topk_high_gradient.csv\n",
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "    patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "99   C3N-02768   0.000078       0.000078             0              1\n",
      "97   C3N-02768   0.000079       0.000079             0              1\n",
      "98   C3N-02768   0.000079       0.000079             0              1\n",
      "163  C3N-03190   0.000267       0.000267             0              1\n",
      "162  C3N-03190   0.000268       0.000268             0              1\n",
      "161  C3N-03190   0.000268       0.000268             0              1\n",
      "193  C3N-01379   0.000461       0.000461             0              1\n",
      "192  C3N-01379   0.000463       0.000463             0              1\n",
      "191  C3N-01379   0.000463       0.000463             0              1\n",
      "108  C3N-01168   0.001755       0.001755             0              1\n",
      "109  C3N-01168   0.001755       0.001755             0              1\n",
      "164  C3N-03086   0.001871       0.001871             0              1\n",
      "147  C3L-01158   0.001873       0.001873             0              1\n",
      "148  C3L-01158   0.001873       0.001873             0              1\n",
      "165  C3N-03086   0.001874       0.001874             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "    patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "107  C3L-01637   0.022225       0.022225             0              1\n",
      "106  C3L-01637   0.022224       0.022224             0              1\n",
      "133  C3N-00516   0.021881       0.021881             0              1\n",
      "134  C3N-00516   0.021770       0.021770             0              1\n",
      "94   C3L-01054   0.021065       0.021065             0              1\n",
      "96   C3L-01054   0.021058       0.021058             0              1\n",
      "95   C3L-01054   0.021058       0.021058             0              1\n",
      "74   C3N-02940   0.020042       0.020042             0              1\n",
      "76   C3N-02940   0.020033       0.020033             0              1\n",
      "75   C3N-02940   0.020032       0.020032             0              1\n",
      "58   C3N-03666   0.019919       0.019919             0              1\n",
      "135  C3N-00516   0.019498       0.019498             0              1\n",
      "189  C3N-01900   0.019239       0.019239             0              1\n",
      "188  C3N-01900   0.019232       0.019232             0              1\n",
      "190  C3N-01900   0.019228       0.019228             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_mixed50TEST/fold_4_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_mixed50TEST/fold_4_topk/topk_high_gradient.csv\n"
     ]
    }
   ],
   "source": [
    "ct_path=\"../MedImageInsights/embeddings_output_cptacpda_93\"\n",
    "wsi_path=\"../../TitanCPTACPDA/20x_512px_0px_overlap/slide_features_titan\"\n",
    "output_dir = \"./interpretability/interpretability_PDA_mixed50TEST\"\n",
    "folds_dir = \"./models/ckpts/CPTACPDA_trainmixed50_multival_Titan_MedImSight_new\"\n",
    "test_path = \"./data/processed/processed_CPTAC_PDA_test/k=all.tsv\"\n",
    "\n",
    "\n",
    "evaluate_and_log(folds_dir,ct_path,wsi_path,test_path,output_dir,batch_size=16, n_folds=5)\n",
    "for i in range(5):\n",
    "    csv_input = f\"./interpretability/interpretability_PDA_mixed50TEST/fold_{i}_log.csv\"\n",
    "    find_topk_gradient_extremes(\n",
    "        csv_path=csv_input,\n",
    "        k=15,\n",
    "        output_dir=f\"./interpretability/interpretability_PDA_mixed50TEST/fold_{i}_topk\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b735d",
   "metadata": {},
   "source": [
    "## CPTAC UCEC test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bd4ef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3606097/1337002563.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(fold_dir, model_subdir, model_file), map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Top-k LOW |Gradient Norm| Samples:\n",
      "    patient_id  grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "0    C3L-04473        0.0            0.0             0              1\n",
      "177  C3L-01662        0.0            0.0             0              1\n",
      "178  C3L-01662        0.0            0.0             0              1\n",
      "179  C3L-01662        0.0            0.0             0              1\n",
      "180  C3L-01662        0.0            0.0             0              1\n",
      "181  C3L-01160        0.0            0.0             0              1\n",
      "182  C3L-01160        0.0            0.0             0              1\n",
      "183  C3L-01160        0.0            0.0             0              1\n",
      "184  C3N-03884        0.0            0.0             0              1\n",
      "185  C3N-03884        0.0            0.0             0              1\n",
      "186  C3N-03884        0.0            0.0             0              1\n",
      "187  C3L-01031        0.0            0.0             0              1\n",
      "188  C3L-01031        0.0            0.0             0              1\n",
      "189  C3L-01031        0.0            0.0             0              1\n",
      "190  C3L-04027        0.0            0.0             0              1\n",
      "\n",
      "üî∏ Top-k HIGH |Gradient Norm| Samples:\n",
      "    patient_id     grad_norm  abs_grad_norm  ct_available  wsi_available\n",
      "136  C3N-02768  2.288209e-08   2.288209e-08             0              1\n",
      "264  C3N-03853  2.288209e-08   2.288209e-08             0              1\n",
      "208  C3L-02809  2.288209e-08   2.288209e-08             0              1\n",
      "63   C3N-01719  2.288209e-08   2.288209e-08             0              1\n",
      "62   C3N-01719  2.288209e-08   2.288209e-08             0              1\n",
      "220  C3N-03190  2.288209e-08   2.288209e-08             0              1\n",
      "55   C3N-04284  2.288209e-08   2.288209e-08             0              1\n",
      "92   C3N-03439  2.288209e-08   2.288209e-08             0              1\n",
      "35   C3N-03069  2.288209e-08   2.288209e-08             0              1\n",
      "248  C3L-03388  2.288209e-08   2.288209e-08             0              1\n",
      "166  C3L-00102  2.288209e-08   2.288209e-08             0              1\n",
      "162  C3L-01052  2.288209e-08   2.288209e-08             0              1\n",
      "257  C3N-03211  2.288209e-08   2.288209e-08             0              1\n",
      "118  C3L-02604  2.288209e-08   2.288209e-08             0              1\n",
      "105  C3L-02701  2.288209e-08   2.288209e-08             0              1\n",
      "\n",
      "üìÅ Saved to:\n",
      "  ./interpretability/interpretability_PDA_testmixed50/fold_0_topk/topk_low_gradient.csv\n",
      "  ./interpretability/interpretability_PDA_testmixed50/fold_0_topk/topk_high_gradient.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import csv\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from data.multimodal_features_surv import MultimodalCTWSIDatasetSurv\n",
    "from models.dpe.main_model_nobackbone_surv_new_gcs import MADPENetNoBackbonesSurv\n",
    "\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "class CoxLoss(_WeightedLoss):\n",
    "    def forward(self, hazard_pred: torch.Tensor, survtime: torch.Tensor, censor: torch.Tensor):\n",
    "        censor = censor.float()\n",
    "        n = len(survtime)\n",
    "        R_mat = survtime.reshape((1, n)) >= survtime.reshape((n, 1))\n",
    "        theta = hazard_pred.reshape(-1)\n",
    "        exp_theta = torch.exp(theta)\n",
    "        loss = -torch.mean((theta - torch.log(torch.sum(exp_theta * R_mat, dim=1))) * censor)\n",
    "        return loss\n",
    "\n",
    "\n",
    "cox_loss_fn = CoxLoss()\n",
    "\n",
    "def compute_grad_and_curvature(fused_features, hazard, survtime, censor):\n",
    "    hazard = hazard.view(-1)\n",
    "    loss = cox_loss_fn(hazard, survtime, censor)\n",
    "    grad_f = torch.autograd.grad(loss, fused_features, create_graph=True)[0]\n",
    "    grad_norm = grad_f.flatten(1).norm(p=2, dim=1)\n",
    "\n",
    "    random_vec = grad_f.detach().clone().sign()\n",
    "    grad_dot_random = torch.sum(grad_f * random_vec)\n",
    "    hvp = torch.autograd.grad(grad_dot_random, fused_features, retain_graph=False)[0]\n",
    "    curvature = torch.sum(hvp * random_vec, dim=list(range(1, hvp.ndim)))\n",
    "    \n",
    "    #print(\"grad_f_att:\", grad_f)\n",
    "    #print(\"grad_norm:\", grad_f.flatten(1).norm(p=2, dim=1))\n",
    "\n",
    "    \n",
    "    return grad_norm.detach().cpu().numpy(), curvature.detach().cpu().numpy()   \n",
    "\n",
    "def evaluate_and_log():\n",
    "    folds_dir = \"./models/ckpts/CPTACPDA_trainmixed50_multival_Titan_MedImSight\"\n",
    "    test_path = \"./data/processed/processed_CPTAC_PDA_test/k=all.tsv\"\n",
    "    ct_path = \"../MedImageInsights/embeddings_output_cptacpda_93\"\n",
    "    wsi_path = \"../../TitanCPTACPDA/20x_512px_0px_overlap/slide_features_titan\"\n",
    "    output_dir = \"./interpretability/interpretability_PDA_testmixed50\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for fold in range(1):\n",
    "        print(f\"\\n=== Fold {fold} ===\")\n",
    "        model = MADPENetNoBackbonesSurv(\n",
    "            rad_input_dim=1024, histo_input_dim=768,\n",
    "            inter_dim=256, token_dim=256, dim_hider=256\n",
    "        )\n",
    "        model.eval()\n",
    "\n",
    "        # Load checkpoint\n",
    "        fold_dir = os.path.join(folds_dir, f\"fold_{fold}\")\n",
    "        model_subdir = next(d for d in os.listdir(fold_dir) if os.path.isdir(os.path.join(fold_dir, d)))\n",
    "        model_file = next(f for f in os.listdir(os.path.join(fold_dir, model_subdir)) if f.endswith(\"mixed_missing.pth\"))\n",
    "        checkpoint = torch.load(os.path.join(fold_dir, model_subdir, model_file), map_location=\"cpu\")\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        dataset = MultimodalCTWSIDatasetSurv(\n",
    "            fold=fold,\n",
    "            split=\"train\",\n",
    "            ct_path=ct_path,\n",
    "            wsi_path=wsi_path,\n",
    "            labels_splits_path=test_path,\n",
    "            missing_modality_prob=0.0,\n",
    "            require_both_modalities=False,\n",
    "            pairing_mode=\"one_to_one\",\n",
    "            allow_repeats=True,\n",
    "            pairs_per_patient=None,\n",
    "            missing_modality=\"wsi\"\n",
    "        )\n",
    "\n",
    "        loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "        # CSV Logger\n",
    "        log_file = os.path.join(output_dir, f\"fold_{fold}_log.csv\")\n",
    "        fold_tensor_dir = os.path.join(output_dir, f\"fold_{fold}\")\n",
    "        os.makedirs(fold_tensor_dir, exist_ok=True)\n",
    "\n",
    "        with open(log_file, \"w\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([\n",
    "                \"patient_id\", \"ct_path\", \"wsi_path\",\n",
    "                \"ct_available\", \"wsi_available\",\n",
    "                \"hazard_score\", \"survtime\", \"censor\",\n",
    "                \"grad_norm\", \"curvature\",\n",
    "                \"fused_path\", \"pe_path\", \"hazard_tensor_path\"\n",
    "            ])\n",
    "\n",
    "            for i, batch in enumerate(loader):\n",
    "                for k in batch:\n",
    "                    if isinstance(batch[k], torch.Tensor):\n",
    "                        batch[k] = batch[k].float()\n",
    "\n",
    "                with torch.enable_grad():\n",
    "                    for k in batch:\n",
    "                        if isinstance(batch[k], torch.Tensor):\n",
    "                            batch[k].requires_grad = True\n",
    "\n",
    "                    outputs = model(\n",
    "                        batch[\"ct_feature\"],\n",
    "                        batch[\"wsi_feature\"],\n",
    "                        modality_flag=batch[\"modality_mask\"],\n",
    "                        output_layers=[\"hazard\", \"fused_features\", \"positional_embeddings\"]\n",
    "                    )\n",
    "                    fused_features = outputs[\"fused_features\"]\n",
    "                    fused_features.requires_grad_(True)\n",
    "\n",
    "                    # Recompute hazard *outside* the model to ensure it is explicitly tied to fused_features\n",
    "                    hazard = model.hazard_net(fused_features)\n",
    "\n",
    "                    #fused_features = outputs[\"fused_features\"]\n",
    "                    pos_emb = outputs[\"positional_embeddings\"].squeeze()\n",
    "                    #fused_features.requires_grad_(True)\n",
    "                    grad_norm, curvature = compute_grad_and_curvature(\n",
    "                        fused_features, hazard, batch[\"survtime\"], batch[\"censor\"]\n",
    "                    )\n",
    "\n",
    "                # Save tensor files\n",
    "                sample_id = f\"sample_{i:04d}\"\n",
    "                fused_path = os.path.join(fold_tensor_dir, f\"{sample_id}_fused.npy\")\n",
    "                pe_path = os.path.join(fold_tensor_dir, f\"{sample_id}_pe.npy\")\n",
    "                hazard_path = os.path.join(fold_tensor_dir, f\"{sample_id}_hazard.npy\")\n",
    "\n",
    "                np.save(fused_path, fused_features.detach().cpu().numpy())\n",
    "                np.save(pe_path, pos_emb.detach().cpu().numpy())\n",
    "                np.save(hazard_path, hazard.detach().cpu().numpy())\n",
    "\n",
    "                ct_flag = int(batch[\"modality_mask\"][0, 0].item())\n",
    "                wsi_flag = int(batch[\"modality_mask\"][0, 1].item())\n",
    "\n",
    "                writer.writerow([\n",
    "                    batch[\"patient_id\"][0],\n",
    "                    dataset.samples[i][\"ct_path\"],\n",
    "                    dataset.samples[i][\"wsi_feature\"],\n",
    "                    ct_flag, wsi_flag,\n",
    "                    hazard.item(),\n",
    "                    batch[\"survtime\"].item(),\n",
    "                    batch[\"censor\"].item(),\n",
    "                    grad_norm[0],\n",
    "                    curvature[0],\n",
    "                    fused_path,\n",
    "                    pe_path,\n",
    "                    hazard_path\n",
    "                ])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_and_log()\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "def find_topk_gradient_extremes(\n",
    "    csv_path: str,\n",
    "    k: int = 10,\n",
    "    output_dir: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds top-k highest and lowest |gradient norm| samples from a CSV log.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to fold_X_log.csv generated during eval.\n",
    "        k (int): Number of top and bottom samples to retrieve.\n",
    "        output_dir (str): Optional folder to save CSVs. If None, only prints results.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if \"grad_norm\" not in df.columns:\n",
    "        raise ValueError(\"The CSV does not contain 'grad_norm' column.\")\n",
    "\n",
    "    # Compute absolute gradient norms\n",
    "    df[\"abs_grad_norm\"] = df[\"grad_norm\"].abs()\n",
    "\n",
    "    # Sort by absolute gradient norm\n",
    "    df_sorted = df.sort_values(by=\"abs_grad_norm\", ascending=True)\n",
    "\n",
    "    topk_low = df_sorted.head(k).copy()\n",
    "    topk_high = df_sorted.tail(k).copy()[::-1]  # High to low\n",
    "\n",
    "    print(\"\\nüîπ Top-k LOW |Gradient Norm| Samples:\")\n",
    "    print(topk_low[[\"patient_id\", \"grad_norm\", \"abs_grad_norm\", \"ct_available\", \"wsi_available\"]])\n",
    "\n",
    "    print(\"\\nüî∏ Top-k HIGH |Gradient Norm| Samples:\")\n",
    "    print(topk_high[[\"patient_id\", \"grad_norm\", \"abs_grad_norm\", \"ct_available\", \"wsi_available\"]])\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        low_path = os.path.join(output_dir, \"topk_low_gradient.csv\")\n",
    "        high_path = os.path.join(output_dir, \"topk_high_gradient.csv\")\n",
    "        topk_low.to_csv(low_path, index=False)\n",
    "        topk_high.to_csv(high_path, index=False)\n",
    "        print(f\"\\nüìÅ Saved to:\\n  {low_path}\\n  {high_path}\")\n",
    "\n",
    "    return topk_low, topk_high\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    for i in range(1):\n",
    "        csv_input = f\"./interpretability/interpretability_PDA_testmixed50/fold_{i}_log.csv\"\n",
    "        find_topk_gradient_extremes(\n",
    "            csv_path=csv_input,\n",
    "            k=15,\n",
    "            output_dir=f\"./interpretability/interpretability_PDA_testmixed50/fold_{i}_topk\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_biocv_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
